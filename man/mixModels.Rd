% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/interfaceMixModels.R
\name{mixModelsTrain}
\alias{mixModelsTrain}
\alias{mixmodels}
\alias{mixModelsTrain,matrix-method}
\alias{mixModelsTrain,DataFrame-method}
\alias{mixModelsTrain,MultiAssayExperiment-method}
\alias{mixModelsPredict}
\alias{mixModelsPredict,MixModelsListsSet,matrix-method}
\alias{mixModelsPredict,MixModelsListsSet,DataFrame-method}
\alias{mixModelsPredict,MixModelsListsSet,MultiAssayExperiment-method}
\title{Classification based on Differential Distribution utilising Mixtures of
Normals}
\usage{
\S4method{mixModelsTrain}{matrix}(measurementsTrain, ...)

\S4method{mixModelsTrain}{DataFrame}(measurementsTrain, classesTrain, ..., verbose = 3)

\S4method{mixModelsTrain}{MultiAssayExperiment}(
  measurementsTrain,
  targets = names(measurementsTrain),
  classesTrain,
  ...
)

\S4method{mixModelsPredict}{MixModelsListsSet,matrix}(models, measurementsTest, ...)

\S4method{mixModelsPredict}{MixModelsListsSet,DataFrame}(
  models,
  measurementsTest,
  difference = c("unweighted", "weighted"),
  weighting = c("height difference", "crossover distance"),
  densityXvalues = 1024,
  minDifference = 0,
  returnType = c("both", "class", "score"),
  verbose = 3
)

\S4method{mixModelsPredict}{MixModelsListsSet,MultiAssayExperiment}(
  models,
  measurementsTest,
  targets = names(measurementsTest),
  ...
)
}
\arguments{
\item{measurementsTrain}{Either a \code{\link{matrix}}, \code{\link{DataFrame}}
or \code{\link{MultiAssayExperiment}} containing the training data.  For a
\code{matrix} or \code{\link{DataFrame}}, the rows are samples, and the columns are features.
If of type \code{\link{DataFrame}} or \code{\link{MultiAssayExperiment}}, the data set is subset
to only those features of type \code{numeric}.}

\item{...}{Variables not used by the \code{matrix} nor the
\code{MultiAssayExperiment} method which are passed into and used by the
\code{DataFrame} method or extra arguments for training passed to
\code{\link[Rmixmod]{mixmodCluster}}. The argument \code{nbCluster} is
mandatory.}

\item{classesTrain}{A vector of class labels of class \code{\link{factor}} of the
same length as the number of samples in \code{measurementsTrain} if it is a
\code{\link{matrix}} or a \code{\link{DataFrame}} or a character vector of length 1
containing the column name in \code{measurementsTrain} if it is a \code{\link{DataFrame}} or the
column name in \code{colData(measurementsTrain)} if \code{measurementsTrain} is a
\code{\link{MultiAssayExperiment}}. If a column name, that column will be
removed before training.}

\item{verbose}{Default: 3. A number between 0 and 3 for the amount of
progress messages to give.  This function only prints progress messages if
the value is 3.}

\item{targets}{If \code{measurements} is a \code{MultiAssayExperiment}, the
names of the data tables to be used. \code{"sampleInfo"} is also a valid value
and specifies that numeric variables from the clinical data table will be
used.}

\item{models}{A \code{MixModelsListsSet} of models generated by the
training function and training class information. There is one element for
each class. Another element at the end of the list has the class sizes of
the classes in the training data.}

\item{measurementsTest}{An object of the same class as \code{measurementsTrain} with no
samples in common with \code{measurementsTrain} and the same number of features
as it.}

\item{difference}{Default: \code{"unweighted"}. Either \code{"unweighted"}
or \code{"weighted"}. In weighted mode, the difference in densities is
summed over all features. If unweighted mode, each feature's vote is worth
the same. Both can be calculated simultaneously.}

\item{weighting}{Default: \code{"height difference"}. Either \code{"height
difference"}, or \code{"crossover distance"}. The type of weight to
calculate. For \code{"height difference"}, the weight of each prediction is
equal to the sum of the vertical distances for all of the mixture components
within one class subtracted from the sum of the components of the other
class, summed for each value of x. For \code{"crossover distance"}, the x
positions where the mixture density of the class being considered crosses
another class' density is firstly calculated. The predicted class is the
class with the highest mixture sum at the particular value of x and the
weight is the distance of x from the nearest density crossover point.}

\item{densityXvalues}{Default: 1024. Only relevant when \code{weight} is
\code{"crossover distance"}.  The number of equally-spaced locations at
which to calculate y values for each mixture density.}

\item{minDifference}{Default: 0. The minimum difference in sums of mixture
densities between the class with the highest sum and the class with the
second highest sum for a feature to be allowed to vote. If no features for
a particular sample have a difference large enough, the class predicted is
simply the largest class.}

\item{returnType}{Default: \code{"both"}. Either \code{"class"},
\code{"score"} or \code{"both"}.  Sets the return value from the prediction
to either a vector of predicted classes, a matrix of scores with columns
corresponding to classes, as determined by the factor levels of
\code{classesTrain}, or both a column of predicted classes and columns of class
scores in a \code{data.frame}.}
}
\value{
For \code{mixModelsTrain}, a list of trained models of class
\code{\link[Rmixmod:MixmodCluster-class]{MixmodCluster}}.  For
\code{mixModelsPredict}, a vector of class prediction information
(i.e. classes and/or scores), as long as the number of samples in the test
data.
}
\description{
Fits mixtures of normals for every feature, separately for each class.
}
\details{
If \code{weighted} is \code{TRUE}, then a sample's predicted class is the
class with the largest sum of weights, each scaled for the number of samples
in the training data of each class. Otherwise, when \code{weighted} is
\code{FALSE}, each feature has an equal vote, and votes for the class with
the largest weight, scaled for class sizes in the training set.

If \code{weight} is \code{"crossover distance"}, the crossover points are
computed by considering the distance between y values of the two densities
at every x value. x values for which the sign of the difference changes
compared to the difference of the closest lower value of x are used as the
crossover points.
}
\examples{

  # First 25 samples and first 5 genes are mixtures of two normals. Last 25 samples are
  # one normal.
  
  genesMatrix <- t(sapply(1:25, function(geneColumn) c(rnorm(5, sample(c(5, 15), replace = TRUE, 5)))))
  genesMatrix <- rbind(genesMatrix, sapply(1:5, function(geneColumn) c(rnorm(25, 9, 1))))
  genesMatrix <- cbind(genesMatrix, sapply(1:5, function(geneColumn) rnorm(50, 9, 1)))
  rownames(genesMatrix) <- paste("Sample", 1:50)
  colnames(genesMatrix) <- paste("Gene", 1:10)
  classes <- factor(rep(c("Poor", "Good"), each = 25), levels = c("Good", "Poor"))
  
  trainSamples <- c(1:15, 26:40)
  testSamples <- c(16:25, 41:50)
  selected <- 1:5
  
  trained <- mixModelsTrain(genesMatrix[trainSamples, selected], classes[trainSamples],
                            nbCluster = 1:3)
  mixModelsPredict(trained, genesMatrix[testSamples, selected])

}
\author{
Dario Strbenac
}
