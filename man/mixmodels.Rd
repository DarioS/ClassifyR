\name{mixmodels}
\alias{mixmodels}
\alias{mixModelsTrain}
\alias{mixModelsTrain,matrix-method}
\alias{mixModelsTrain,ExpressionSet-method}
\alias{mixModelsTest}
\alias{mixModelsTest,list,matrix-method}
\alias{mixModelsTest,list,ExpressionSet-method}
\title{Selection of Differential Distributions with Mixtures of Normals}
\description{Fits mixtures of normals for every gene, separately for each class.
       }
\usage{
  \S4method{mixModelsTrain}{matrix}(expression, classes, ...)
  \S4method{mixModelsTrain}{ExpressionSet}(expression, ..., verbose = 3)
  \S4method{mixModelsTest}{list,matrix}(models, test, ...)
  \S4method{mixModelsTest}{list,ExpressionSet}(models, test,
            weighted = c("both", "unweighted", "weighted"), minDifference = 0, verbose = 3)  
}
\arguments{
  \item{expression}{Either a \code{\link{matrix}} or \code{\link{ExpressionSet}} containing
                    the training data. For a matrix, the rows are features, and the columns
                    are samples.}
  \item{test}{Either a \code{\link{matrix}} or \code{\link{ExpressionSet}} containing
                    the test data. For a matrix, the rows are features, and the columns
                    are samples.}                    
  \item{classes}{A vector of class labels.}
  \item{weighted}{In weighted mode, the difference in densities is summed over all features.
                  If unweighted mode, each features's vote is worth the same. To save
                  computational time, both can be calculated simultaneously.}
  \item{minDifference}{The minimum difference in densities for a feature to be allowed
                       to vote. Can be a vector of cutoffs.}                                 
  \item{...}{For the training or testing function with \code{\link{matrix}} dispatch,
             arguments passed to the function with \code{\link{ExpressionSet}} dispatch.
             For the training function with \code{\link{ExpressionSet}} dispatch,
             extra arguments passed to \code{\link[Rmixmod]{mixmodCluster}}. The argument \code{nbCluster}
             is mandatory.}                       
  \item{models}{A list of length 2 of models generated by the training function.
                The first element has mixture models the same length as the number
                of features in the expression data for one class. The second element
                has the same information for the other class.}
  \item{verbose}{A number between 0 and 3 for the amount of progress messages to give.
                 A higher number will produce more messages.}
}
\details{
  For weighted voting, the difference between probability density, scaled for the number
  of samples of each class used in training, is summed for all features. For unweighted voting,
  each feature votes based on the scaled density difference with the same strength.
}
\value{
  For \code{mixModelsTrain}, a list of trained models of class \code{\link[Rmixmod:MixmodCluster-class]{MixmodCluster}}.
  For \code{mixModelsTest}, either a factor of predicted classes for the test data, or lists of factors,
  if both weighted and unweighted voting or a range of \code{minDifference} values was provided.
}
\author{Dario Strbenac}

\examples{
  # First 25 samples are mixtures of two normals. Last 25 samples are one normal.
  genesMatrix <- sapply(1:25, function(geneColumn) c(rnorm(50, 5, 1), rnorm(50, 15, 1)))
  genesMatrix <- cbind(genesMatrix, sapply(1:25, function(geneColumn) rnorm(100, 9, 3)))
  classes <- factor(rep(c("Poor", "Good"), each = 25))
  trained <- mixModelsTrain(genesMatrix, classes, nbCluster = 1:3)
  mixModelsTest(trained, genesMatrix, minDifference = 1:3)
}
