\name{mixmodels}
\alias{mixmodels}
\alias{mixModelsTrain}
\alias{mixModelsTrain,matrix-method}
\alias{mixModelsTrain,ExpressionSet-method}
\alias{mixModelsTest}
\alias{mixModelsTest,list,matrix-method}
\alias{mixModelsTest,list,ExpressionSet-method}
\title{Selection of Differential Distributions with Mixtures of Normals}
\description{Fits mixtures of normals for every gene, separately for each class.
       }
\usage{
  \S4method{mixModelsTrain}{matrix}(expression, classes, ...)
  \S4method{mixModelsTrain}{ExpressionSet}(expression, ..., verbose = 3)
  \S4method{mixModelsTest}{list,matrix}(models, test, ...)
  \S4method{mixModelsTest}{list,ExpressionSet}(models, test,
            weighted = c("both", "unweighted", "weighted"), minDifference = 0,
            returnType = c("label", "score", "both"), verbose = 3)  
}
\arguments{
  \item{expression}{Either a \code{\link{matrix}} or \code{\link{ExpressionSet}} containing
                    the training data. For a matrix, the rows are features, and the columns
                    are samples.}
  \item{test}{Either a \code{\link{matrix}} or \code{\link{ExpressionSet}} containing
                    the test data. For a matrix, the rows are features, and the columns
                    are samples.}                    
  \item{classes}{A vector of class labels.}
  \item{weighted}{In weighted mode, the difference in densities is summed over all features.
                  If unweighted mode, each features's vote is worth the same. To save
                  computational time, both can be calculated simultaneously.}
  \item{minDifference}{The minimum difference in densities for a feature to be allowed
                       to vote. Can be a vector of cutoffs.}                                 
  \item{...}{For the training or testing function with \code{\link{matrix}} dispatch,
             arguments passed to the function with \code{\link{ExpressionSet}} dispatch.
             For the training function with \code{\link{ExpressionSet}} dispatch,
             extra arguments passed to \code{\link[Rmixmod]{mixmodCluster}}. The argument \code{nbCluster}
             is mandatory.}                       
  \item{models}{A list of length 2 of models generated by the training function.
                The first element has mixture models the same length as the number
                of features in the expression data for one class. The second element
                has the same information for the other class.}
  \item{returnType}{Either \code{"label"}, \code{"score"}, or \code{"both"}. Sets the return value
                    from the prediction to either a vector of class labels, score for a sample belonging
                    to the second class, as determined by the factor levels, or both labels and scores
                    in a \code{\link{data.frame}}.}                     
  \item{verbose}{A number between 0 and 3 for the amount of progress messages to give.
                 A higher number will produce more messages.}
}
\details{
  For weighted voting, the difference between probability density, scaled for the number
  of samples of each class used in training, is summed for all features. For unweighted voting,
  each feature votes based on the scaled density difference with the same strength.
  
  For unweighted classification, the score is the number of features which voted for the second class,
  divided by the features which voted. For weighted classification, the score is the sum of scaled
  differences in densities.  
}
\value{
  For \code{mixModelsTrain}, a list of trained models of class \code{\link[Rmixmod:MixmodCluster-class]{MixmodCluster}}.
  A vector or list of class prediction information, as long as the number of samples in the test data,
  or lists of such information, if both weighted and unweighted voting or a range of \code{minDifference}
  values was provided.
}
\author{Dario Strbenac}

\examples{
  # First 25 samples are mixtures of two normals. Last 25 samples are one normal.
  genesMatrix <- sapply(1:25, function(geneColumn) c(rnorm(50, 5, 1), rnorm(50, 15, 1)))
  genesMatrix <- cbind(genesMatrix, sapply(1:25, function(geneColumn) rnorm(100, 9, 3)))
  classes <- factor(rep(c("Poor", "Good"), each = 25))
  trained <- mixModelsTrain(genesMatrix, classes, nbCluster = 1:3)
  mixModelsTest(trained, genesMatrix, minDifference = 1:3)
}
