% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/interfaceElasticNetGLM.R
\name{elasticNetGLMtrainInterface}
\alias{elasticNetGLMtrainInterface}
\alias{elasticNetGLMinterface}
\alias{elasticNetGLMpredictInterface}
\alias{elasticNetGLMtrainInterface,matrix-method}
\alias{elasticNetGLMtrainInterface,DataFrame-method}
\alias{elasticNetGLMtrainInterface,MultiAssayExperiment-method}
\alias{elasticNetGLMpredictInterface,multnet,matrix-method}
\alias{elasticNetGLMpredictInterface,multnet,DataFrame-method}
\alias{elasticNetGLMpredictInterface,multnet,MultiAssayExperiment-method}
\title{An Interface for glmnet Package's glmnet Function}
\usage{
elasticNetGLMtrainInterface(measurementsTrain, ...)
}
\arguments{
\item{measurementsTrain}{Either a \code{\link{matrix}}, \code{\link{DataFrame}}
or \code{\link{MultiAssayExperiment}} containing the training data.  For a
\code{matrix} or \code{\link{DataFrame}}, the rows are samples, and the columns are features.
If of type \code{\link{DataFrame}} or \code{\link{MultiAssayExperiment}}, the data set is subset
to only those features of type \code{numeric}.}

\item{...}{Variables not used by the \code{matrix} nor the
\code{MultiAssayExperiment} method which are passed into and used by the
\code{DataFrame} method (e.g. \code{verbose}) or, for the training function,
options that are used by the \code{glmnet} function. For the testing
function, this variable simply contains any parameters passed from the
classification framework to it which aren't used by glmnet's \code{predict}
fuction.}

\item{classesTrain}{A vector of class labels of class \code{\link{factor}} of the
same length as the number of samples in \code{measurementsTrain} if it is a
\code{\link{matrix}} or a \code{\link{DataFrame}} or a character vector of length 1
containing the column name in \code{measurementsTrain} if it is a \code{\link{DataFrame}} or the
column name in \code{colData(measurementsTrain)} if \code{measurementsTrain} is a
\code{\link{MultiAssayExperiment}}. If a column name, that column will be
removed before training.}

\item{lambda}{The lambda value passed directly to
\code{\link[glmnet]{glmnet}} if the training function is used or passed as
\code{s} to \code{\link[glmnet]{predict.glmnet}} if the prediction function
is used.}

\item{measurementsTest}{An object of the same class as \code{measurementsTrain} with no
samples in common with \code{measurementsTrain} and the same number of features
as it.}

\item{targets}{If \code{measurementsTrain} is a \code{MultiAssayExperiment}, the
names of the data tables to be used. \code{"sampleInfo"} is also a valid value
and specifies that integer variables from the sample information data table will be
used.}

\item{model}{A trained elastic net GLM, as created by the \code{glmnet}
function.}

\item{returnType}{Default: \code{"both"}. Either \code{"class"},
\code{"score"} or \code{"both"}.  Sets the return value from the prediction
to either a vector of class labels, matrix of scores for each class, or both
labels and scores in a \code{data.frame}.}

\item{verbose}{Default: 3. A number between 0 and 3 for the amount of
progress messages to give.  This function only prints progress messages if
the value is 3.}
}
\value{
For \code{elasticNetGLMtrainInterface}, an object of type
\code{glmnet}. For \code{elasticNetGLMpredictInterface}, either a factor
vector of predicted classes, a matrix of scores for each class, or a table
of both the class labels and class scores, depending on the setting of
\code{returnType}.
}
\description{
An elastic net GLM classifier uses a penalty which is a combination of a
lasso penalty and a ridge penalty, scaled by a lambda value, to fit a sparse
linear model to the data.
}
\details{
The value of the \code{family} parameter is fixed to \code{"multinomial"} so
that classification with more than 2 classes is possible and
\code{type.multinomial} is fixed to \code{"grouped"} so that a grouped lasso
penalty is used. During classifier training, if more than one lambda value
is considered by specifying a vector of them as input or leaving the default
value of NULL, then the chosen value is determined based on classifier
resubstitution error rate.
}
\examples{

  if(require(glmnet))
  {
    # Genes 76 to 100 have differential expression.
    genesMatrix <- sapply(1:100, function(sample) rnorm(25, 9, 0.3))
    genesMatrix <- rbind(genesMatrix, t(sapply(1:25, function(sample)
                                      c(rnorm(75, 9, 0.3), rnorm(25, 14, 0.3)))))
    classes <- factor(rep(c("Poor", "Good"), each = 25))
    rownames(genesMatrix) <- paste("Sample", 1:nrow(genesMatrix))
    colnames(genesMatrix) <- paste("Gene", 1:ncol(genesMatrix))
    
    CVparams <- CrossValParams("k-Fold")
      
    trainParams <- TrainParams(elasticNetGLMtrainInterface, nlambda = 500)
    predictParams <- PredictParams(elasticNetGLMpredictInterface)
    modParams <- ModellingParams(selectParams = NULL, trainParams = trainParams,
                                   predictParams = predictParams)
    classified <- runTests(genesMatrix, classes, CVparams, modParams)
                           
    classified <- calcCVperformance(classified, "Balanced Error")
    head(tunedParameters(classified))
    performance(classified)
  }
  
}
\author{
Dario Strbenac
}
