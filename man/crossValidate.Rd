% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/crossValidate.R
\name{crossValidate}
\alias{crossValidate}
\alias{crossValidate,matrix-method}
\alias{crossValidate,DataFrame-method}
\alias{crossValidate,MultiAssayExperiment-method,}
\alias{crossValidate,data.frame-method}
\title{Cross-validation to evaluate classification performance.}
\usage{
\S4method{crossValidate}{DataFrame}(
  measurements,
  classes,
  nFeatures = 20,
  selectionMethod = "t_test",
  selectionOptimisation = "Resubstitution",
  classifier = "randomForest",
  multiViewMethod = "none",
  dataCombinations = NULL,
  nFolds = 5,
  nRepeats = 20,
  nCores = 1,
  characteristicsLabel = NULL
)
}
\arguments{
\item{measurements}{Either a \code{\link{DataFrame}}, \code{\link{data.frame}}, \code{\link{matrix}}, \code{\link{MultiAssayExperiment}} 
or a list of these objects containing the training data.  For a
\code{matrix} and \code{data.frame}, the rows are samples and the columns are features. For a \code{data.frame} or \code{\link{MultiAssayExperiment}}
the rows are features and the columns are samples as is typical in Bioconductor.}

\item{classes}{A vector of class labels of class \code{\link{factor}} of the
same length as the number of samples in \code{measurements} or a character vector of length 1 containing the
column name in \code{measurements} if it is a \code{\link{DataFrame}} or the
column name in \code{colData(measurements)} if \code{measurements} is a \code{\link{MultiAssayExperiment}}. If a column name, that column will be
removed before training.}

\item{nFeatures}{The number of features to be used for classification. If this is a single number, the same number of features will be used for all comparisons
or datasets. If a numeric vector these will be optimised over using \code{selectionOptimisation}. If a named vector with the same names of multiple datasets, 
a different number of features will be used for each dataset. If a named list of vectors, the respective number of features will be optimised over. 
Set to NULL or "all" if all features should be used.}

\item{selectionMethod}{A character vector of feature selection methods to compare. If a named character vector with names corresponding to different datasets, 
and performing multiview classification, the respective classification methods will be used on each dataset.}

\item{selectionOptimisation}{A character of "Resubstitution", "Nested CV" or "none" specifying the approach used to optimise nFeatures.}

\item{classifier}{A character vector of classification methods to compare. If a named character vector with names corresponding to different datasets, 
and performing multiview classification, the respective classification methods will be used on each dataset.}

\item{multiViewMethod}{A character vector specifying the multiview method or data integration approach to use.}

\item{dataCombinations}{A character vector or list of character vectors proposing the datasets or, in the case of a list, combination of datasets to use
with each element being a vector of datasets to combine.}

\item{nFolds}{A numeric specifying the number of folds to use for cross-validation.}

\item{nRepeats}{A numeric specifying the the number of repeats or permutations to use for cross-validation.}

\item{nCores}{A numeric specifying the number of cores used if the user wants to use parallelisation.}

\item{characteristicsLabel}{A character specifying an additional label for the cross-validation run.}
}
\value{
An object of class \code{\link{ClassifyResult}}
}
\description{
This function has been designed to faciliate the comparison of classification
 methods using cross-validation. A selection of typical 
comparisons are implemented.
}
\details{
\code{selectionMethod} can be any of the following implemented approaches - randomForest, elasticNet, logistic, svm, dlda or naiveBayes. 

\code{classifier} can be any of the following implemented approaches -  none, t_test, limma, edgeR, NSC, bartlette, levene, DMD, likelihood, KS or KL.

\code{multiViewMethod} can take a few different values. Using \code{merge} will merge or bind the datasets after feature selection. 
 Using \code{prevlidation} will build prevalidated vectors on all the datasets except the clinical data. There must be a dataset called clinical.
 Using \code{pca} will perform pca on each dataset and then merge the top few components with the clinical data. There must be a dataset called clinical.
}
\examples{

data(asthma)

# Compare randomForest and svm classifiers.
result <- crossValidate(measurements, classes, classifier = c("randomForest", "svm"))
Boxplot(result)


# Compare performance of different datasets. 
# First make a toy example dataset with multiple data types. We'll randomly assign different features to be clinical, gene or protein.
set.seed(51773)
measurements <- DataFrame(t(measurements))
mcols(measurements)$dataset <- c(rep("clinical",20),sample(c("gene", "protein"), ncol(measurements)-20, replace = TRUE))
mcols(measurements)$feature <- colnames(measurements)

# We'll use different nFeatures for each dataset. We'll also use repeated cross-validation with 5 repeats for speed in the example.
set.seed(51773)
result <- crossValidate(measurements, classes, nFeatures = c(clinical = 5, gene = 20, protein = 30), classifier = "randomForest", nRepeats = 5)
Boxplot(result)

# Merge different datasets. But we will only do this for two combinations. If dataCombinations is not specified it would attempt all combinations.
set.seed(51773)
result <- crossValidate(measurements, classes, dataCombinations = list(c("clinical", "protein"), c("clinical", "gene")), multiViewMethod = "merge", nRepeats = 5)
Boxplot(resultMerge)


Boxplot(c(result, resultMerge))
}
