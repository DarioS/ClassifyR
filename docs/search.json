[{"path":"/articles/ClassifyR.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Getting Started with ClassifyR","text":"Typically, feature selection method classifier originates different R package, ClassifyR provides wrapper around. default, high-performance t-test/F-test random forest installed. intend compare numerous different modelling methods, install suggested packages using command BiocManager::install(\"ClassifyR\", dependencies = TRUE). take minutes, particularly Linux, package compiled source code.","code":""},{"path":"/articles/ClassifyR.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Getting Started with ClassifyR","text":"ClassifyR provides structured pipeline cross-validated classification. Classification viewed terms four stages, data transformation, feature selection, classifier training, prediction. driver functions crossValidate runTests implements varieties cross-validation. : Permutation order samples followed k-fold cross-validation (runTests ) Repeated x% test set cross-validation leave-k-cross-validation Driver functions can use parallel processing capabilities R speed cross-validations many CPUs available. output driver functions ClassifyResult object can directly used performance evaluation functions. process classification summarised flowchart. Importantly, ClassifyR implements number methods classification using different kinds changes measurements classes. classifiers work features means different. addition changes means (DM), ClassifyR also allows classification using differential variability (DV; changes scale) differential distribution (DD; changes location /scale).","code":""},{"path":"/articles/ClassifyR.html","id":"case-study-diagnosing-asthma","dir":"Articles","previous_headings":"Overview","what":"Case Study: Diagnosing Asthma","title":"Getting Started with ClassifyR","text":"demonstrate key features ClassifyR, data set consisting 2000 variably expressed genes 190 people used quickly obtain results. journal article corresponding data set published Scientific Reports 2018 titled Nasal Brush-based Classifier Asthma Identified Machine Learning Analysis Nasal RNA Sequence Data. Load package. glimpse RNA measurements sample classes. numeric matrix variable measurements stores normalised values RNA gene abundances sample factor vector classes identifies class samples belong . measurements normalised using DESeq2’s varianceStabilizingTransformation function, produces \\(log_2\\)-like data. complex data sets multiple kinds experiments (e.g. DNA methylation, copy number, gene expression set samples) MultiAssayExperiment recommended data storage supported ClassifyR’s methods.","code":"library(ClassifyR) data(asthma) # Contains measurements and classes variables. measurements[1:5, 1:5] ##            HBB BPIFA1  XIST FCGR3B HBA2 ## Sample 1  9.72  14.06 12.28  11.42 7.83 ## Sample 2 11.98  13.89  6.35  13.25 9.42 ## Sample 3 12.15  17.44 10.21   7.87 9.68 ## Sample 4 10.60  11.87  6.27  14.75 8.96 ## Sample 5  8.18  15.01 11.21   6.77 6.43 head(classes) ## [1] No  No  No  No  Yes No  ## Levels: No Yes"},{"path":"/articles/ClassifyR.html","id":"quick-start-crossvalidate-function","dir":"Articles","previous_headings":"","what":"Quick Start: crossValidate Function","title":"Getting Started with ClassifyR","text":"crossValidate function offers quick simple way start analysing dataset ClassifyR. wrapper runTests, core model building testing function ClassifyR. crossValidate must supplied measurements, simple tabular data container list-like structure related tabular data common samples. classes may matrix, data.frame, DataFrame, MultiAssayExperiment list data.frames. dataset \\(n\\) observations \\(p\\) variables, crossValidate function accept inputs following shapes: crossValidate must also supplied outcome, represents prediction made variety possible ways. factor contains class label observation. classes must length \\(n\\). character length 1 matches column name data frame holds classes. classes automatically removed training done. Surv object length number samples data contains information time censoring samples. character vector length 2 3 match column name data frame holds information time censoring samples. time--event columns automatically removed training done. type classifier used can changed classifier argument. default random forest, seamlessly handles categorical numerical data. full list classifiers can seen running ?crossValidate. feature selection step can performed classification using nFeatures selectionMethod, t-test default. Similarly, number folds number repeats cross validation can changed nFolds nRepeats arguments. wanted, nCores can specified run cross validation parallel. perform 5-fold cross-validation Support Vector Machine 2 repeats:","code":"result <- crossValidate(measurements, classes, classifier = \"SVM\",                         nFeatures = 20, nFolds = 5, nRepeats = 2, nCores = 1) performancePlot(result) ## Warning in .local(results, ...): Balanced Accuracy not found in all elements of results. Calculating it now."},{"path":"/articles/ClassifyR.html","id":"data-integration-with-crossvalidate","dir":"Articles","previous_headings":"Quick Start: crossValidate Function","what":"Data Integration with crossValidate","title":"Getting Started with ClassifyR","text":"crossValidate also allows data multiple sources integrated single model. integration method can specified multiViewMethod argument. example, suppose first 10 variables asthma data set certain source remaining 1990 variables second source. integrate multiple data sets, variable must labeled data set came . done different manner depending data type measurements. using Bioconductor’s DataFrame, can specified using mcols. column metadata, feature must assay feature name.  using list data.frames, name element list used assay name.","code":"measurementsDF <- DataFrame(measurements) mcols(measurementsDF) <- data.frame(   assay = rep(c(\"assay_1\", \"assay_2\"), times = c(10, 1990)),   feature = colnames(measurementsDF) )  result <- crossValidate(measurementsDF, classes, classifier = \"SVM\", nFolds = 5,                         nRepeats = 3, multiViewMethod = \"merge\")  performancePlot(result, characteristicsList = list(x = \"Assay Name\")) ## Warning in .local(results, ...): Balanced Accuracy not found in all elements of results. Calculating it now. # Assigns first 10 variables to dataset_1, and the rest to dataset_2 measurementsList <- list(   (measurements |> as.data.frame())[1:10],   (measurements |> as.data.frame())[11:2000] ) names(measurementsList) <- c(\"assay_1\", \"assay_2\")  result <- crossValidate(measurementsList, classes, classifier = \"SVM\", nFolds = 5,                         nRepeats = 3, multiViewMethod = \"merge\")  performancePlot(result, characteristicsList = list(x = \"Assay Name\")) ## Warning in .local(results, ...): Balanced Accuracy not found in all elements of results. Calculating it now."},{"path":"/articles/ClassifyR.html","id":"a-more-detailed-look-at-classifyr","dir":"Articles","previous_headings":"","what":"A More Detailed Look at ClassifyR","title":"Getting Started with ClassifyR","text":"following sections, useful functions provided ClassifyR demonstrated. However, user wrap feature selection, training, prediction function classification framework, long meets simple rules input return parameters. See appendix section guide titled “Rules New Functions” description .","code":""},{"path":"/articles/ClassifyR.html","id":"comparison-to-existing-classification-frameworks","dir":"Articles","previous_headings":"A More Detailed Look at ClassifyR","what":"Comparison to Existing Classification Frameworks","title":"Getting Started with ClassifyR","text":"frameworks classification R. table provides comparison features offer.","code":""},{"path":"/articles/ClassifyR.html","id":"provided-functionality","dir":"Articles","previous_headings":"A More Detailed Look at ClassifyR","what":"Provided Functionality","title":"Getting Started with ClassifyR","text":"Although cross-validation framework, number popular feature selection classification functions provided package meet requirements functions used (see last section).","code":""},{"path":"/articles/ClassifyR.html","id":"provided-methods-for-feature-selection-and-classification","dir":"Articles","previous_headings":"A More Detailed Look at ClassifyR > Provided Functionality","what":"Provided Methods for Feature Selection and Classification","title":"Getting Started with ClassifyR","text":"following tables, function used function explicitly specified user shown functionName. functions produce ranking, different size subsets tried classifier performance evaluated, select best subset features, based criterion balanced accuracy rate, example. Likewise, variety classifiers also provided. * ordinary numeric measurements transformed absolute deviations using subtractFromLocation. † value kernel “linear”. desired selection classification method already implemented, rules writing functions work ClassifyR outlined wrapper vignette. Please visit information.","code":""},{"path":"/articles/ClassifyR.html","id":"provided-meta-feature-methods","dir":"Articles","previous_headings":"A More Detailed Look at ClassifyR > Provided Functionality","what":"Provided Meta-feature Methods","title":"Getting Started with ClassifyR","text":"number methods provided users enable classification feature-set-centric interactor-centric way. meta-feature creation functions used cross-validation done.","code":""},{"path":"/articles/ClassifyR.html","id":"fine-grained-cross-validation-and-modelling-using-runtests","dir":"Articles","previous_headings":"A More Detailed Look at ClassifyR","what":"Fine-grained Cross-validation and Modelling Using runTests","title":"Getting Started with ClassifyR","text":"control finer aspects cross-validation single data set, runTests may employed place crossValidate. variety cross-validation, parameters specified CrossValParams object. default setting 100 permutations five folds parameter tuning done resubstitution. also recommended specify parallelParams setting. Linux MacOS operating systems, MulticoreParam Windows computers SnowParam. Note option RNGseed needs set user classifiers feature selection functions element randomisation. One example works operating systems, best-suited Windows : actual operations data build model , stages specified object class ModellingParams. controls class imbalance handled (default downsample smallest class), transformation needs done inside cross-validation (.e. involving computed value training set), feature selection training prediction functions used. default ordinary t-test (two groups) ANOVA (three groups) classification using diagonal LDA.","code":"CVparams <- CrossValParams(parallelParams = SnowParam(16, RNGseed = 123)) CVparams ModellingParams() ## An object of class \"ModellingParams\" ## Slot \"balancing\": ## [1] \"downsample\" ##  ## Slot \"transformParams\": ## NULL ##  ## Slot \"selectParams\": ## An object of class 'SelectParams'. ## Selection Name: Difference in Means. ##  ## Slot \"trainParams\": ## An object of class 'TrainParams'. ## Classifier Name: Diagonal LDA. ##  ## Slot \"predictParams\": ## An object of class 'PredictParams'. ##  ## Slot \"doImportance\": ## [1] FALSE"},{"path":"/articles/ClassifyR.html","id":"runtests-driver-function-of-cross-validated-classification","dir":"Articles","previous_headings":"A More Detailed Look at ClassifyR","what":"runTests Driver Function of Cross-validated Classification","title":"Getting Started with ClassifyR","text":"runTests main function ClassifyR handles sample splitting parallelisation, used, cross-validation. begin , simple classifier demonstrated. uses t-test ANOVA ranking (depending number classes) feature ranking DLDA classification. classifier relies differences means classes. parameters need specified, default classification runTests. default, number features tuned resubstitution training set. , 5 permutations (non-default) 5 folds cross-validation (default) specified. computers 1 CPU, number cores use can given runTests using argument parallelParams. parameter seed important set result reproducibility cross-validation , employs randomisation partition samples folds. Also, RNGseed highly recommended set back-end specified BPPARAM parallel processing. first seed mentioned work parallel processes. details runTests parameter classes used , consult help pages functions.","code":"crossValParams <- CrossValParams(permutations = 5) DMresults <- runTests(measurements, classes, crossValParams, verbose = 1)"},{"path":"/articles/ClassifyR.html","id":"evaluation-of-a-classification","dir":"Articles","previous_headings":"","what":"Evaluation of a Classification","title":"Getting Started with ClassifyR","text":"frequently selected gene can identified using distribution function relative abundance values samples can displayed visually plotFeatureClasses.  means abundance levels C10orf95 substantially different people without asthma. plotFeatureClasses can also plot categorical data, may found clinical data table, bar chart. Classification error rates, well many prediction performance measures, can calculated calcCVperformance. Next, balanced accuracy rate calculated considering samples, test set . balanced accuracy rate defined average rate correct classifications class. See documentation calcCVperformance list performance metrics may calculated. error rate 20%. vector predictions vector actual classes available, old study use ClassifyR cross-validation, calcExternalPerformance can used pair factor vectors length.","code":"selectionPercentages <- distribution(DMresults, plot = FALSE) head(selectionPercentages) sortedPercentages <- head(selectionPercentages[order(selectionPercentages, decreasing = TRUE)]) head(sortedPercentages) mostChosen <- sortedPercentages[1] bestGenePlot <- plotFeatureClasses(measurements, classes, names(mostChosen), dotBinWidth = 0.1,                                    xAxisLabel = \"Normalised Expression\") ## allFeaturesText ##    ANKK1   ANKMY1 ARHGAP39     B9D1     B9D2 C10orf95  ##        4        8       72        4        4      100  ## allFeaturesText ## C10orf95    SSBP4   ZDHHC1    CROCC    CTXN1    NAT14  ##      100      100      100       96       88       76 DMresults <- calcCVperformance(DMresults) DMresults ## An object of class 'ClassifyResult'. ## Characteristics: ##    characteristic                   value ##    Selection Name     Difference in Means ##   Classifier Name            Diagonal LDA ##  Cross-validation 5 Permutations, 5 Folds ## Features: List of length 25 of feature identifiers. ## Predictions: A data frame of 950 rows. ## Performance Measures: AUC, Balanced Accuracy. performance(DMresults) ## $AUC ##    1    2    3    4    5  ## 0.86 0.90 0.89 0.86 0.89  ##  ## $`Balanced Accuracy` ##         1         2         3         4         5  ## 0.8128055 0.8042522 0.8002199 0.7810362 0.7810362"},{"path":"/articles/ClassifyR.html","id":"comparison-of-different-classifications","dir":"Articles","previous_headings":"Evaluation of a Classification","what":"Comparison of Different Classifications","title":"Getting Started with ClassifyR","text":"samplesMetricMap function allows visual comparison sample-wise error rate accuracy measures different ClassifyResult objects. Firstly, classifier run uses Kullback-Leibler divergence ranking resubstitution error feature selection heuristic naive Bayes classifier classification. classification use features either change location scale classes. naive Bayes kernel classifier default uses vertical distance class densities can instead use horizontal distance nearest non-zero density cross-point confidently classify samples tails densities. per-sample classification accuracy automatically calculated differential means differential distribution classifiers plotted samplesMetricMap.  benefit plot allows easy identification samples hard classify explained considering additional information . Differential distribution class prediction appears biased majority class (Asthma). traditionally, distribution performance values complete cross-validation can visualised performancePlot providing list function. default draw box plots, violin plots also made. default performance metric plot balanced accuracy. ’s already calculated classifications, case DD, done automatically.  can observe spread balanced accuracy rates small, slightly wider differential distribution classifier. features ranked selected feature selection stage can compared within classifiers plotting functions rankingPlot selectionPlot. Consider task visually representing consistent feature rankings top 100 different features differential distribution classifier 5 folds 5 cross-validations.  top-ranked features fairly similar pairs 20 cross-validations. large cross-validation scheme, leave-2-cross-validation, results contains many classifications, many feature set comparisons make. Note rankingPlot selectionPlot parallelParams options allows calculation feature set overlaps done multiple processors.","code":"modellingParamsDD <- ModellingParams(selectParams = SelectParams(\"KL\"),                                      trainParams = TrainParams(\"naiveBayes\"),                                      predictParams = NULL) DDresults <- runTests(measurements, classes, crossValParams, modellingParamsDD, verbose = 1) DDresults ## An object of class 'ClassifyResult'. ## Characteristics: ##    characteristic                       value ##    Selection Name Kullback-Leibler Divergence ##   Classifier Name          Naive Bayes Kernel ##  Cross-validation     5 Permutations, 5 Folds ## Features: List of length 25 of feature identifiers. ## Predictions: A data frame of 950 rows. ## Performance Measures: None calculated yet. resultsList <- list(Abundance = DMresults, Distribution = DDresults) samplesMetricMap(resultsList, showXtickLabels = FALSE) ## Warning in .local(results, ...): Sample Accuracy not found in all elements of results. Calculating it now. ## Warning: Removed 2 rows containing missing values (`geom_tile()`). ## TableGrob (2 x 1) \"arrange\": 2 grobs ##   z     cells    name                grob ## 1 1 (2-2,1-1) arrange      gtable[layout] ## 2 2 (1-1,1-1) arrange text[GRID.text.533] performancePlot(resultsList) ## Warning in .local(results, ...): Balanced Accuracy not found in all elements of results. Calculating it now. rankingPlot(DDresults, topRanked = 1:100, xLabelPositions = c(1, seq(10, 100, 10)))"},{"path":"/articles/ClassifyR.html","id":"generating-a-roc-plot","dir":"Articles","previous_headings":"Evaluation of a Classification","what":"Generating a ROC Plot","title":"Getting Started with ClassifyR","text":"classifiers can output scores probabilities representing likely sample one classes, instead , well , class labels. enables different score thresholds tried, generate pairs false positive false negative rates. naive Bayes classifier used previously default returnType parameter set “”, class predictions scores stored classification result. diagonal LDA. case, data frame class predictions scores class returned classifier cross-validation framework. Setting returnType “score” classifier option also sufficient generate ROC plot. Many existing classifiers R packages also option allows score probability calculated. default, scores different iterations prediction merged one line drawn per classification. Alternatively, setting mode = “average” consider iteration prediction separately, average also calculate draw confidence intervals. default interval 95% interval customisable setting interval.  ROC plot shows classifiability asthma data set high. examples functions output scores fisherDiscriminant, DLDApredictInterface, SVMpredictInterface.","code":"ROCplot(resultsList, fontSizes = c(24, 12, 12, 12, 12))"},{"path":"/articles/ClassifyR.html","id":"other-use-cases","dir":"Articles","previous_headings":"","what":"Other Use Cases","title":"Getting Started with ClassifyR","text":"Apart cross-validation one data set, ClassifyR can used couple ways.","code":""},{"path":"/articles/ClassifyR.html","id":"using-an-independent-test-set","dir":"Articles","previous_headings":"Other Use Cases","what":"Using an Independent Test Set","title":"Getting Started with ClassifyR","text":"Sometimes, cross-validation unnecessary. happens studies large sample sizes designed large number samples prespecified form test set. classifier trained training sample set, makes predictions test sample set. can achieved using function runTest directly. See documentation required inputs.","code":""},{"path":"/articles/ClassifyR.html","id":"cross-validating-selected-features-on-a-different-data-set","dir":"Articles","previous_headings":"Other Use Cases","what":"Cross-validating Selected Features on a Different Data Set","title":"Getting Started with ClassifyR","text":"cross-validated classification complete, usefulness features selected may explored another dataset. previousSelection function takes existing ClassifyResult object returns features selected equivalent iteration currently processed. necessary, models trained one data set directly transferrable new dataset; classifier training (e.g. choosing thresholds, fitting model coefficients) redone. course, features new dataset naming system ones old dataset.","code":""},{"path":"/articles/ClassifyR.html","id":"parameter-tuning","dir":"Articles","previous_headings":"Other Use Cases","what":"Parameter Tuning","title":"Getting Started with ClassifyR","text":"feature ranking methods classifiers allow choosing tuning parameters, controls aspect model learning. example parameter tuning linear SVM presented. particular SVM single tuning parameter, cost. Higher values parameter penalise misclassifications . Moreover, feature selection happens using feature ranking function trying range top-ranked features see gives best performance, range specified list element named nFeatures performance type (e.g. Balanced Accuracy) specified list element named performanceType. Therefore, kind parameter tuning always happens, even feature ranking classifier function explicit tuning parameters. Tuning achieved ClassifyR providing variable called tuneParams SelectParams TrainParams constructor. tuneParams named list, names names tuning variables, except one named “performanceType” specifies performance metric use picking parameter values. non-sample-specific performance metrics calcCVperformance calculates can optimised. index chosen parameters, well combinations parameters associated performance metric, stored every validation, can accessed tunedParameters function. cost value 1 10 appears often chosen.","code":"tuneList <- list(cost = c(0.01, 0.1, 1, 10)) SVMparams <- ModellingParams(trainParams = TrainParams(\"SVM\", kernel = \"linear\", tuneParams = tuneList),                              predictParams = PredictParams(\"SVM\")) SVMresults <- runTests(measurements, classes, crossValParams, SVMparams) length(tunedParameters(SVMresults)) ## [1] 25 tunedParameters(SVMresults)[1:5] ## [[1]] ## [[1]]$tuneCombinations ##    topN  cost Balanced Accuracy ## 1    10  0.01         0.8022680 ## 2    20  0.01         0.8066514 ## 3    30  0.01         0.8211359 ## 4    40  0.01         0.8356204 ## 5    50  0.01         0.8261864 ## 6    60  0.01         0.8645893 ## 7    70  0.01         0.8972746 ## 8    80  0.01         0.8885077 ## 9    90  0.01         0.8885077 ## 10  100  0.01         0.8885077 ## 11   10  0.10         0.8400038 ## 12   20  0.10         0.8268534 ## 13   30  0.10         0.8406709 ## 14   40  0.10         0.9181437 ## 15   50  0.10         0.9231942 ## 16   60  0.10         0.9093768 ## 17   70  0.10         0.9477797 ## 18   80  0.10         0.9477797 ## 19   90  0.10         0.9477797 ## 20  100  0.10         0.9572136 ## 21   10  1.00         0.8369545 ## 22   20  1.00         0.8652563 ## 23   30  1.00         0.8854584 ## 24   40  1.00         0.9282447 ## 25   50  1.00         0.9471126 ## 26   60  1.00         0.9565466 ## 27   70  1.00         0.9716981 ## 28   80  1.00         0.9905660 ## 29   90  1.00         0.9905660 ## 30  100  1.00         1.0000000 ## 31   10 10.00         0.8369545 ## 32   20 10.00         0.8564894 ## 33   30 10.00         0.8999428 ## 34   40 10.00         0.8679245 ## 35   50 10.00         1.0000000 ## 36   60 10.00         1.0000000 ## 37   70 10.00         1.0000000 ## 38   80 10.00         1.0000000 ## 39   90 10.00         1.0000000 ## 40  100 10.00         1.0000000 ##  ## [[1]]$bestIndex ## [1] 30 ##  ##  ## [[2]] ## [[2]]$tuneCombinations ##    topN  cost Balanced Accuracy ## 1    10  0.01         0.8073185 ## 2    20  0.01         0.7978845 ## 3    30  0.01         0.8167524 ## 4    40  0.01         0.8160854 ## 5    50  0.01         0.8167524 ## 6    60  0.01         0.8312369 ## 7    70  0.01         0.8696398 ## 8    80  0.01         0.8790738 ## 9    90  0.01         0.8928912 ## 10  100  0.01         0.9124261 ## 11   10  0.10         0.8022680 ## 12   20  0.10         0.8841243 ## 13   30  0.10         0.9029922 ## 14   40  0.10         0.8602058 ## 15   50  0.10         0.9043263 ## 16   60  0.10         0.9043263 ## 17   70  0.10         0.9225272 ## 18   80  0.10         0.9231942 ## 19   90  0.10         0.9326282 ## 20  100  0.10         0.9521631 ## 21   10  1.00         0.7985516 ## 22   20  1.00         0.8986087 ## 23   30  1.00         0.9043263 ## 24   40  1.00         0.8999428 ## 25   50  1.00         0.9521631 ## 26   60  1.00         0.9615971 ## 27   70  1.00         0.9622642 ## 28   80  1.00         0.9811321 ## 29   90  1.00         1.0000000 ## 30  100  1.00         1.0000000 ## 31   10 10.00         0.7796836 ## 32   20 10.00         0.8999428 ## 33   30 10.00         0.7968363 ## 34   40 10.00         0.9332952 ## 35   50 10.00         0.9949495 ## 36   60 10.00         1.0000000 ## 37   70 10.00         1.0000000 ## 38   80 10.00         1.0000000 ## 39   90 10.00         1.0000000 ## 40  100 10.00         1.0000000 ##  ## [[2]]$bestIndex ## [1] 29 ##  ##  ## [[3]] ## [[3]]$tuneCombinations ##    topN  cost Balanced Accuracy ## 1    10  0.01         0.8123690 ## 2    20  0.01         0.8123690 ## 3    30  0.01         0.8029350 ## 4    40  0.01         0.8218029 ## 5    50  0.01         0.8174195 ## 6    60  0.01         0.8362874 ## 7    70  0.01         0.8413379 ## 8    80  0.01         0.8413379 ## 9    90  0.01         0.8696398 ## 10  100  0.01         0.8885077 ## 11   10  0.10         0.8275205 ## 12   20  0.10         0.8746903 ## 13   30  0.10         0.8652563 ## 14   40  0.10         0.8608729 ## 15   50  0.10         0.8898418 ## 16   60  0.10         0.8948923 ## 17   70  0.10         0.9231942 ## 18   80  0.10         0.9188107 ## 19   90  0.10         0.9332952 ## 20  100  0.10         0.9144273 ## 21   10  1.00         0.8564894 ## 22   20  1.00         0.9036592 ## 23   30  1.00         0.9093768 ## 24   40  1.00         0.9093768 ## 25   50  1.00         0.9289118 ## 26   60  1.00         0.9194778 ## 27   70  1.00         0.9477797 ## 28   80  1.00         0.9622642 ## 29   90  1.00         0.9811321 ## 30  100  1.00         0.9905660 ## 31   10 10.00         0.8854584 ## 32   20 10.00         0.9043263 ## 33   30 10.00         0.9326282 ## 34   40 10.00         0.7917858 ## 35   50 10.00         0.8301887 ## 36   60 10.00         0.9811321 ## 37   70 10.00         1.0000000 ## 38   80 10.00         1.0000000 ## 39   90 10.00         1.0000000 ## 40  100 10.00         1.0000000 ##  ## [[3]]$bestIndex ## [1] 37 ##  ##  ## [[4]] ## [[4]]$tuneCombinations ##    topN  cost Balanced Accuracy ## 1    10  0.01         0.7847341 ## 2    20  0.01         0.8218029 ## 3    30  0.01         0.8180865 ## 4    40  0.01         0.8753573 ## 5    50  0.01         0.8797408 ## 6    60  0.01         0.8703068 ## 7    70  0.01         0.8703068 ## 8    80  0.01         0.8753573 ## 9    90  0.01         0.8854584 ## 10  100  0.01         0.9043263 ## 11   10  0.10         0.8180865 ## 12   20  0.10         0.8659234 ## 13   30  0.10         0.8672575 ## 14   40  0.10         0.9376787 ## 15   50  0.10         0.9521631 ## 16   60  0.10         0.9427292 ## 17   70  0.10         0.9521631 ## 18   80  0.10         0.9427292 ## 19   90  0.10         0.9572136 ## 20  100  0.10         0.9666476 ## 21   10  1.00         0.8281875 ## 22   20  1.00         0.8766914 ## 23   30  1.00         0.8672575 ## 24   40  1.00         0.9760816 ## 25   50  1.00         0.9855155 ## 26   60  1.00         0.9949495 ## 27   70  1.00         0.9855155 ## 28   80  1.00         0.9949495 ## 29   90  1.00         0.9949495 ## 30  100  1.00         1.0000000 ## 31   10 10.00         0.8325710 ## 32   20 10.00         0.8817419 ## 33   30 10.00         0.8062702 ## 34   40 10.00         0.9949495 ## 35   50 10.00         1.0000000 ## 36   60 10.00         1.0000000 ## 37   70 10.00         1.0000000 ## 38   80 10.00         1.0000000 ## 39   90 10.00         1.0000000 ## 40  100 10.00         1.0000000 ##  ## [[4]]$bestIndex ## [1] 30 ##  ##  ## [[5]] ## [[5]]$tuneCombinations ##    topN  cost Balanced Accuracy ## 1    10  0.01         0.8057692 ## 2    20  0.01         0.7861538 ## 3    30  0.01         0.7957692 ## 4    40  0.01         0.8200000 ## 5    50  0.01         0.8396154 ## 6    60  0.01         0.8300000 ## 7    70  0.01         0.8442308 ## 8    80  0.01         0.8830769 ## 9    90  0.01         0.8926923 ## 10  100  0.01         0.9173077 ## 11   10  0.10         0.8780769 ## 12   20  0.10         0.8976923 ## 13   30  0.10         0.8876923 ## 14   40  0.10         0.9123077 ## 15   50  0.10         0.9126923 ## 16   60  0.10         0.8984615 ## 17   70  0.10         0.9273077 ## 18   80  0.10         0.9226923 ## 19   90  0.10         0.9130769 ## 20  100  0.10         0.9323077 ## 21   10  1.00         0.8784615 ## 22   20  1.00         0.8976923 ## 23   30  1.00         0.8984615 ## 24   40  1.00         0.9369231 ## 25   50  1.00         0.9465385 ## 26   60  1.00         0.9369231 ## 27   70  1.00         0.9515385 ## 28   80  1.00         0.9950000 ## 29   90  1.00         0.9853846 ## 30  100  1.00         1.0000000 ## 31   10 10.00         0.8784615 ## 32   20 10.00         0.9076923 ## 33   30 10.00         0.9223077 ## 34   40 10.00         0.8457692 ## 35   50 10.00         0.9853846 ## 36   60 10.00         1.0000000 ## 37   70 10.00         1.0000000 ## 38   80 10.00         1.0000000 ## 39   90 10.00         1.0000000 ## 40  100 10.00         1.0000000 ##  ## [[5]]$bestIndex ## [1] 30"},{"path":"/articles/ClassifyR.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Getting Started with ClassifyR","text":"ClassifyR framework cross-validated classification provides variety unique functions performance evaluation. provides wrappers many popular classifiers designed extensible classifiers desired.","code":""},{"path":"/articles/ClassifyR.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Getting Started with ClassifyR","text":"Strbenac D., Yang, J., Mann, G.J. Ormerod, J. T. (2015) ClassifyR: R package performance assessment classification applications transcriptomics, Bioinformatics, 31(11):1851-1853  Strbenac D., Mann, G.J., Yang, J. Ormerod, J. T. (2016) Differential distribution improves gene selection stability competitive classification performance patient survival, Nucleic Acids Research, 44(13):e119","code":""},{"path":"/articles/DevelopersGuide.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"**ClassifyR** Developer's Guide","text":"ClassifyR regularly maintained new functionality often added. may done users ClassifyR. guide summarise technical concepts ClassifyR works assist users contribute new functionality package understanding design principles ClassifyR. Almost functions ClassifyR S4 methods, added benefit checking type input data matches required. Basic variables R strict type, unlike programming languages.","code":""},{"path":[]},{"path":"/articles/DevelopersGuide.html","id":"input-data-types","dir":"Articles","previous_headings":"New Model Building Function Requirements","what":"Input Data Types","title":"**ClassifyR** Developer's Guide","text":"Data used predictive modelling can take many shapes forms. ClassifyR ensure three valid input types matrix, DataFrame MultiAssayExperiment DataFrame sent modelling function. Importantly, ClassifyR implements number methods classification using different kinds changes measurements classes. classifiers work features means different. addition changes means (DM), ClassifyR also allows classification using differential variability (DV; changes scale) differential distribution (DD; changes location /scale).","code":""},{"path":"/articles/DevelopersGuide.html","id":"registering-the-function","dir":"Articles","previous_headings":"New Model Building Function Requirements","what":"Registering the Function","title":"**ClassifyR** Developer's Guide","text":"ClassifyR keeps track functions used model building, allow automated naming axes labels tick marks nice format. , function pretty name associated file constants.R. Firstly, find .ClassifyRenvir[[\"functionsTable\"]] file, basically two-column matrix stored environment add new function pretty name additional row matrix. Secondly, convenience cross-validation function named crossValidate. allows convenient specification feature selection modelling combinations keywords. add new feature ranking method, add new entry .selectionKeywordToFunction utilities.R adding new keyword function pair. similar statement R file modelling functions, new classifier, instance, added.","code":""},{"path":"/articles/DevelopersGuide.html","id":"documenting-the-function","dir":"Articles","previous_headings":"New Model Building Function Requirements","what":"Documenting the Function","title":"**ClassifyR** Developer's Guide","text":"Firstly, main vignette, couple tables summarising feature selection model building functions available. Add function relevant table put tick mark appropriate column(s) summarise kind analysis offers. Secondly, NEWS file inst folder. Add new entry new functionality.","code":""},{"path":"/articles/DevelopersGuide.html","id":"incorprating-changes-into-the-package","dir":"Articles","previous_headings":"New Model Building Function Requirements","what":"Incorprating Changes into the Package","title":"**ClassifyR** Developer's Guide","text":"Please make pull request ClassifyR’s GitHub website. code reviewed added contributor DESCRIPTION file package.","code":""},{"path":"/articles/DevelopersGuide.html","id":"feature-ranking-and-selection","dir":"Articles","previous_headings":"New Model Building Function Requirements","what":"Feature Ranking and Selection","title":"**ClassifyR** Developer's Guide","text":"various functions ClassifyR prioritising features return ranking, best worst, features package takes care actual feature selection process. Based specification range values top features try, set variables either best resubstitution (default) nested cross-validation performance found private function .doSelection. input data may one table collection tables. DataFrame variable type stores metadata variables columns. Therefore, ranking function simply returns numeric indices features ranked best worst.","code":""},{"path":"/articles/DevelopersGuide.html","id":"model-training-function","dir":"Articles","previous_headings":"New Model Building Function Requirements","what":"Model Training Function","title":"**ClassifyR** Developer's Guide","text":"function can return trained model type.","code":""},{"path":"/articles/DevelopersGuide.html","id":"extractor-functions","dir":"Articles","previous_headings":"New Model Building Function Requirements","what":"Extractor Functions","title":"**ClassifyR** Developer's Guide","text":"Sometimes, feature ranking / selection done model trained. Also, trained models implicit feature selection, random forest. new modelling function implicit feature selection, also needs accompanied function extract selected features. See forestFeatures interfaceRandomForest.R one example. return value function needs list length 2. first element features, ranked best worst. second element indicies corresponding selected features. random forest example, feature ranking based variable importance score calculated random forest package (.e. randomForest::importance(forest)) selection based non-zero occurrence variable forest (.e. randomForest::varUsed(forest) > 0). two vectors returned list use ClassifyR.","code":""},{"path":"/articles/DevelopersGuide.html","id":"model-prediction-function","dir":"Articles","previous_headings":"New Model Building Function Requirements","what":"Model Prediction Function","title":"**ClassifyR** Developer's Guide","text":"function, (classifiers, one function training prediction separate prediction function), first parameter needs trained model previous step second parameter needs test data.","code":""},{"path":"/articles/DevelopersGuide.html","id":"new-model-evaluation-function-requirements","dir":"Articles","previous_headings":"","what":"New Model Evaluation Function Requirements","title":"**ClassifyR** Developer's Guide","text":"function must accept list ClassifyResult elements, container class stores useful information cross-validation completed. accessors use access class slots, please see ?ClassifyResult.","code":""},{"path":"/articles/DevelopersGuide.html","id":"coding-style","dir":"Articles","previous_headings":"","what":"Coding Style","title":"**ClassifyR** Developer's Guide","text":"help maintain consistency existing code, please: Use camelCase coding style variable names CamelCase class names. Use vectorised loops lapply mapply. Don’t use loops. Use <- variable assignment rater =. Follow style requirements Bioconductor.","code":""},{"path":"/articles/incorporateNew.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Creating a Wrapper for New Functionality and Registering It","text":"might new transformation / selection / modelling algorithm ’s part ClassifyR might useful others. guide explains necessary steps perform making pull request get new functionality added. core framework dispatches data DataFrame object, new function able accept variable type first argument.","code":""},{"path":"/articles/incorporateNew.html","id":"steps-to-add-a-new-function","dir":"Articles","previous_headings":"","what":"Steps to Add a New Function","title":"Creating a Wrapper for New Functionality and Registering It","text":"Define ordinary R function attach name . useful automated annotation modelling results later. basic outline : Open file constants.R. .ClassifyRenvir[[\"functionsTable\"]] two-column matrix, add row specifying function name nice title use plot labelling. example, Add keyword users use want use function cross-validation one keywords two-column matrices along short one-sentence description. example, new function classifier, added end \"classifyKeywords\" matrix. Depending kind functionality new function provides, add entry either .selectionKeywordToFunction .classifierKeywordToParams functions utilities.R. first function maps feature selection keyword wrapper function second maps classifier keyword pair TrainParams PredictParams objects, specify functions training prediction stages. function classifier, open simpleParams.R define TrainParams PredictParams parameter sets . classifier tuning parameters, good specify small range values try, since crossValidate simplicity doesn’t allow anything keyword specified user. Open vignette vignettes/ClassifyR.Rmd look section heading #### Provided Methods Feature Selection Classification. Add new function appropriate table. Now new function defined described, users able discover using available() R command line results automatically store nice names functions used automatically able shown plots.","code":"newFancyClassifier <- function(measurementsTrain, classesTrain, alpha, ..., verbose = 3) {   # Build a model.   } attr(newFancyClassifier, \"name\") <- \"newFancyClassifier\" .ClassifyRenvir[[\"functionsTable\"]] <- matrix(     ...        ... \"newFancyClassifier\", \"Fancy Classifier\"),     ...        ... .ClassifyRenvir[[\"classifyKeywords\"]] <- matrix(     ...        ... \"fancy\", \"Very good classifier that predicts amazingly well.\"),     ...        ..."},{"path":"/articles/introduction.html","id":"purpose","dir":"Articles","previous_headings":"","what":"Purpose","title":"Introduction to the Concepts of ClassifyR","text":"ClassifyR modelling evaluation framework data sets often multiple kinds measurements made individual, common field bioinformatics. Despite name, also allows model building evaluation survival data. Unlike generic modelling frameworks, seamless integration data set structure. Firstly, allows input commonly-used data formats Bioconductor bioinformatics community MultiAssayExperiment DataFrame. MultiAssayExperiment good way store multiple assays samples DataFrame ideal storing mixed features (.e. numerical categorical), clinicopathological data, also allows metadata columns (features) stored. Secondly, use modelling functions one assay multiple assays follows syntax ease use. data conversion flat table required typical modelling function handled internally. Similarly, whether data set one assay requires relatively simple analysis multiple assays requires complex evaluation assay various methods combining assays (e.g. concatenation, prevalidation) can similarly evaluated ClassifyR. Lastly, ClassifyR allows just evaluation test set predictions evaluation. focus evaluation stability interpretability. example addressed feature selection stability repeated cross-validation sample-wise error rate calculation cross-validation help identify subsets samples difficult classify suggest interesting subgroup individuals.","code":""},{"path":"/articles/introduction.html","id":"crossvalidate-and-runtests-two-ways-to-perform-cross-validation","dir":"Articles","previous_headings":"","what":"crossValidate and runTests: Two Ways to Perform Cross-Validation","title":"Introduction to the Concepts of ClassifyR","text":"Two functions provided enable running cross-validation. cases, crossValidate recommended. provides easier interface limited number options specified simple parameters whereas runTests expects user create S4 parameter set objects using classes TrainParams PredictParams. example, crossValidate offers repeat--fold leave-one-cross-validation whereas runTests additionally offers leave-k-Monte Carlo cross-validation. Also, crossValidate designed multi-view data set evaluation whereas runTests limited support data, concatenating different assays table. One key difference crossValidate uses prespecified range performance tuning values whereas runTests expects tuning parameters specified user. , unless less widely-used form cross-validation desired, crossValidate function use. One special case discovery data set validation data set predetermined research project. Training done discovery set predictions made validation set. case, train predict pair functions can used runTest function control model building parameter settings desired.","code":""},{"path":"/articles/introduction.html","id":"data-input-formats","dir":"Articles","previous_headings":"","what":"Data Input Formats","title":"Introduction to the Concepts of ClassifyR","text":"variety allowed input data formats. Let n denote number samples p denote number features assay. , MultiAssayExperiment data type require features rows samples columns whereas others opposite expectation. single-cell RNA sequencing data, scFeatures recommended transforming per-cell data different per-person biological views.","code":""},{"path":"/articles/introduction.html","id":"data-preparation","dir":"Articles","previous_headings":"","what":"Data Preparation","title":"Introduction to the Concepts of ClassifyR","text":"convenience function prepareData first run input data provided crossValidate runTests counterpart functions independent training validation data set modelling. Basically, prediction functions need non-missing values test samples default remove feature missing value sample, although can changed increasing maxMissingProp zero. features small proportion missing value, recommended impute values replace missing values instead discarding feature using ClassifyR. second preparation used subset numeric input features variable features way reducing dimensionality input data set. topNvariance integer top number features kept modelling. default, variable feature filtering used features used modelling.","code":""},{"path":[]},{"path":"/articles/introduction.html","id":"data-transformation","dir":"Articles","previous_headings":"The Four Stages of Cross-validation","what":"Data Transformation","title":"Introduction to the Concepts of ClassifyR","text":"typically done cross-validation. situation done within cross-validation value derived samples needs calculated using samples test set avoided. example \\(log_2\\)-scaling data particular sample uses information samples, shouldn’t done within cross-validation. However, subtracting feature’s measurements location, mean median, done stage specifying subtractFromLocation used.","code":""},{"path":"/articles/introduction.html","id":"feature-selection","dir":"Articles","previous_headings":"The Four Stages of Cross-validation","what":"Feature Selection","title":"Introduction to the Concepts of ClassifyR","text":"recommended cases. typical data set, small number features, , predictive outcome sample. Providing large number uninformative features classifiers widely known degrade predictive performance. default, t-test ranking choice top-p features based resubstitution error rate used select features, full set approaches can seen R command line running: model training methods perform implicit feature selection. suggested experts field feature selection can harmful classifiers can identify complex non-linear relationships variables feature selection methods detect discard important features. ’s hard rule applies every data set, might worthwhile try modelling without feature selection.","code":"library(ClassifyR) available(\"selectionMethod\") ##    selectionMethod Keyword                                               Description ## 1                     none      Skip selection procedure and use all input features. ## 2                   t-test                                                   T-test. ## 3                    limma                                         Moderated t-test. ## 4                    edgeR                              edgeR likelihood ratio test. ## 5                 Bartlett                   Bartlett's test for different variance. ## 6                   Levene                     Levene's test for different variance. ## 7                      DMD           Differences in means/medians and/or deviations. ## 8          likelihoodRatio              Likelihood ratio test (normal distribution). ## 9                       KS Kolmogorov-Smirnov test for differences in distributions. ## 10                      KL        Kullback-Leibler divergence between distributions. ## 11                   CoxPH           Cox proportional hazards Wald test per-feature. ## 12         randomSelection          Randomly selects a specified number of features."},{"path":"/articles/introduction.html","id":"model-training","dir":"Articles","previous_headings":"The Four Stages of Cross-validation","what":"Model Training","title":"Introduction to the Concepts of ClassifyR","text":"stage involves fitting model training data partition variety models provided package. Apart multivariate naive Bayes voting multivariate mixtures normals voting, others wrappers around functionality provided R packages.","code":"available(\"classifier\") ##      classifier Keyword                                   Description ## 1          randomForest                                Random forest. ## 2                  DLDA        Diagonal Linear Discriminant Analysis. ## 3                   kNN                         k Nearest Neighbours. ## 4                   GLM                          Logistic regression. ## 5         elasticNetGLM       Elastic net GLM multinomial regression. ## 6                   SVM                       Support Vector Machine. ## 7                   NSC                   Nearest Shrunken Centroids. ## 8            naiveBayes Naive Bayes kernel feature voting classifier. ## 9       mixturesNormals Mixture of normals feature voting classifier. ## 10                CoxPH                     Cox proportional hazards. ## 11               CoxNet           Penalised Cox proportional hazards. ## 12 randomSurvivalForest                       Random survival forest. ## 13                  XGB                     Extreme gradient booster."},{"path":"/articles/introduction.html","id":"model-testing","dir":"Articles","previous_headings":"The Four Stages of Cross-validation","what":"Model Testing","title":"Introduction to the Concepts of ClassifyR","text":"Finally, fitted model used predict classes samples used training.","code":""},{"path":"/articles/introduction.html","id":"cross-validation-varieties","dir":"Articles","previous_headings":"","what":"Cross-validation Varieties","title":"Introduction to the Concepts of ClassifyR","text":"number different cross-validation schemes can chosen. choice depends goals study computational running time desired. Next, scheme illustrated visually characteristics described.","code":""},{"path":"/articles/introduction.html","id":"repeated-resampling-and-folding","dir":"Articles","previous_headings":"Cross-validation Varieties","what":"Repeated Resampling and Folding","title":"Introduction to the Concepts of ClassifyR","text":"default approach. repeatedly resamples without replacement divides orderings samples folds. illustrated repeated 5-fold cross-validation. benefit approach sample predicted multiple times using slightly different models trained slightly different training sets, gives indication sample prediction stability (see Performance Evaluation guide details). Ordinary k-fold cross-validation effectively case repeated cross-validation number repeats 1.","code":""},{"path":"/articles/introduction.html","id":"leave-k-out","dir":"Articles","previous_headings":"Cross-validation Varieties","what":"Leave-k-out","title":"Introduction to the Concepts of ClassifyR","text":"possible combinations k samples determined combination used test set remainder samples used training set. illustrated leave-2-cross-validation. Using crossValidate, leave-1-cross-validation possible special case k-fold cross-validation k set number samples data set (.e. nRepeats = nrow(tabularData)). Cross-validation settings runTests specified creating CrossValParams object, value k possible. leave-1-cross-validation used, sample appears test set stability predictions can’t evaluated, although cross-validation finish relatively quickly.","code":""},{"path":"/articles/introduction.html","id":"repeated-resampling-and-percentage-split","dir":"Articles","previous_headings":"Cross-validation Varieties","what":"Repeated Resampling and Percentage Split","title":"Introduction to the Concepts of ClassifyR","text":"Also called Monte Carlo cross-validation, scheme repeatedly resamples get new permutations partitions samples fixed percentage test set remainder training set. \\(x \\%\\) assigned test set time, number times sample appear test set random number approximately \\(x \\div 100 \\times nRepeats\\) times. illustrated 30% test set cross-validation. Next, article Performance Evaluation recommended reading. Please choose Articles menu .","code":""},{"path":"/articles/multiViewMethods.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Multi-view Methods for Modelling of Multiple Data Views","text":"Placeholder.","code":""},{"path":"/articles/performanceEvaluation.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Performance Evaluation of Fitted Models","text":"Model building prediction can evaluated using variety performance metrics. test sample predictions, accuracy stability may interest. repeated cross-validation done, possible consider prediction performance test set also sample. identify subset samples unstable prediction accuracy consistently incorrectly predicted. terms features, selection stability can evaluated repetitions within cross-validation also different cross-validations using different feature selection algorithms. following sections, available performance metric defined recommendations using made.","code":""},{"path":"/articles/performanceEvaluation.html","id":"prediction-performance","dir":"Articles","previous_headings":"","what":"Prediction Performance","title":"Performance Evaluation of Fitted Models","text":"performance metrics calculated calcCVperformance function expects object class ClassifyResult input. also possible calculate performance metric pair factor vectors, one known classes predicted classes, pair survival information stored Surv object predicted risk scores using calcExternalPerformance. See function documentation vector keywords specifying performance metric. Firstly, description metrics categorical outcomes provided. , metrics survival outcomes.","code":""},{"path":"/articles/performanceEvaluation.html","id":"categorical-outcomes","dir":"Articles","previous_headings":"Prediction Performance","what":"Categorical Outcomes","title":"Performance Evaluation of Fitted Models","text":"Outcomes may either class label probabilities scores sample belonging classes.","code":""},{"path":"/articles/performanceEvaluation.html","id":"error-and-accuracy-and-their-balanced-versions","dir":"Articles","previous_headings":"Prediction Performance","what":"Error and Accuracy and Their Balanced Versions","title":"Performance Evaluation of Fitted Models","text":"Error simply proportion test samples whose class incorrectly predicted accuracy proportion correctly predicted. Often, data set substantial class imbalance metrics may appear much better classifier really performs classifier simply predicts samples belong majority class. reason, balanced error balanced accuracy preferable robust class imbalance present. Balanced accuracy default performance metric ClassifyR’s performance function. balanced versions simply calculate performance metric within class average results. example, let’s consider data set eight cats two dogs poorly performing classifier predicts ten samples cats (.e. majority class). balanced accuracy \\(\\frac{8}{8} = 1\\) cats \\(\\frac{0}{2} = 0\\) dogs average \\(0.5\\). words, classifier better predicting classes random. However, ordinary accuracy calculated, misleadingly imply classifier quite accurate, since accuracy \\(\\frac{8}{10} = 0.8\\).","code":""},{"path":"/articles/performanceEvaluation.html","id":"precision-and-recall-macro-and-micro-versions","dir":"Articles","previous_headings":"Prediction Performance > Error and Accuracy and Their Balanced Versions","what":"Precision and Recall, Macro and Micro Versions","title":"Performance Evaluation of Fitted Models","text":"Precision proportion samples predicted belong particular class truly belong samples predicted belong class. Recall proportion samples belonging class predicted belong . metrics can combined different ways. Macro averaging computes metric class separately divides number classes, set predictions class contribute equally average. Micro averaging aggregates performance metric numerator classes separately denominator classes, dividing, classes predicted often contribute strongly final value. example, consider different data set cats, dog fish. dogs small class compared cats fish. Macro micro precision somewhat differ. Let \\(TD\\), \\(TC\\) \\(TF\\), number True (.e. correct) predictions dogs, cats fish respectively. Let \\(AD\\), \\(AC\\) \\(AF\\), number predictions dogs, cats fish respectively. \\[ \\begin{aligned} Precision_{macro} & = \\frac{\\frac{TC}{AC} + \\frac{TD}{AD} + \\frac{TF}{AF}}{3} \\\\ & = \\frac{\\frac{8}{12} + \\frac{2}{2} + \\frac{2}{2}}{3} \\\\ & = 0.89 \\\\ \\\\ Precision_{micro} & = \\frac{TC + TD + TF}{AC + AD + AF} \\\\ & = \\frac{8 + 2 + 2}{12 + 2 + 2} \\\\ & = 0.75 \\end{aligned} \\] can observed micro precision influenced cat predictions since many .","code":""},{"path":"/articles/performanceEvaluation.html","id":"combinations-of-precision-and-recall-f1-score-and-matthews-correlation-coefficient","dir":"Articles","previous_headings":"Prediction Performance > Error and Accuracy and Their Balanced Versions","what":"Combinations of Precision and Recall: F1 Score and Matthews Correlation Coefficient","title":"Performance Evaluation of Fitted Models","text":"formulae F1 score Matthews Correlation Coefficient fairly complicated shown. Basically, key differences F1 score ranges 0 1 whereas Matthews Correlation Coefficient ranges -1 1. F1 score may appear high classifier performs poorly class imbalance Matthews Correlation Coefficient robust class imbalance. F1 score applicable data sets three classes Matthews Correlation Coefficient two-class data sets.","code":""},{"path":"/articles/performanceEvaluation.html","id":"are-under-the-curve","dir":"Articles","previous_headings":"Prediction Performance > Error and Accuracy and Their Balanced Versions","what":"Are Under the Curve","title":"Performance Evaluation of Fitted Models","text":"Many modelling methods can return table class probabilities scores sample belonging class. class, samples ordered decreasing order predicted probability sample adds either true positive rate false positive rate considered turn. generates curve (really step function) true positive rate y-axis false positive rate x-axis. area underneath calculated class averaged one number overall classification performance. classifier ’s better guessing random AUC value 0.5 best value 1.0.","code":""},{"path":"/articles/performanceEvaluation.html","id":"survival-outcomes","dir":"Articles","previous_headings":"Prediction Performance","what":"Survival Outcomes","title":"Performance Evaluation of Fitted Models","text":"Predicted outcomes kind risk score.","code":""},{"path":"/articles/performanceEvaluation.html","id":"c-index-and-sample-wise-c-index","dir":"Articles","previous_headings":"Prediction Performance > Survival Outcomes","what":"C-index and Sample-wise C-index","title":"Performance Evaluation of Fitted Models","text":"concordance index, typically written C-index, based pair-wise comparisons samples. ranges 0 1 uninformative model expected C-index 0.5. schematic illustration Korean Journal Radiology : , samples compared censored, can’t evaluated. Also, sample earlier followup time censored later sample , pair also can’t evaluated. comparable pairs, C-index simply number pairs whose risk scores agreeable actual followup times. ClassifyR extends C-index level individual unique sample-wise C-index calculation. performance metric calculates C-index individual test set allows identification individuals hard predict accurately might able linked interesting underlying biology clinical data.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dario Strbenac. Author, maintainer. Ellis Patrick. Author. Sourish Iyengar. Author. Harry Robertson. Author. Andy Tran. Author. John Ormerod. Author. Graham Mann. Author. Jean Yang. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Strbenac D., Mann G.J., Ormerod, J.T. Yang J.Y.H. (2015) ClassifyR: R package performance assessment classification applications transcriptomics, Bioinformatics, 31(11) 1851-1853.","code":"@Article{,   author = {Dario Strbenac and Graham J Mann and John T Ormerod and Jean Y H Yang},   title = {{ClassifyR}: an {R} package for performance assessment of classification with applications to transcriptomics},   journal = {Bioinformatics},   year = {2015},   volume = {31},   number = {11},   pages = {1851-1853}, }"},{"path":"/index.html","id":"classifyr-performance-evaluation-for-multi-view-data-sets-and-seamless-integration-with-multiassayexperiment-and-bioconductor","dir":"","previous_headings":"","what":"A framework for cross-validated classification problems, with\n       applications to differential variability and differential\n       distribution testing","title":"A framework for cross-validated classification problems, with\n       applications to differential variability and differential\n       distribution testing","text":"ClassifyR’s performance evaluation focuses model stability interpretability. Based repeated cross-validation, possible evaluate feature selection stability also per-sample prediction accuracy. Also, multiple omics data assays samples becoming popular ClassifyR supports range multi-view methods evaluate data view predictive combine data views evaluate multiple views provide superior predictive performance single data view.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A framework for cross-validated classification problems, with\n       applications to differential variability and differential\n       distribution testing","text":"recommended method installing ClassifyR using Bioconductor’s BiocManager installer: code install packages provide feature selection model-building functionality. one two methods desired dependencies option omitted packages providing functionality installed manually.","code":"library(BiocManager) install(\"ClassifyR\", dependencies = TRUE)"},{"path":"/index.html","id":"website","dir":"","previous_headings":"","what":"Website","title":"A framework for cross-validated classification problems, with\n       applications to differential variability and differential\n       distribution testing","text":"Please visit ClassifyR website view main vignette well articles provide -depth explanations various aspects package. Details performance evaluation, multi-view methods contributing wrapper new algorithm package provided.","code":""},{"path":"/index.html","id":"reference","dir":"","previous_headings":"","what":"Reference","title":"A framework for cross-validated classification problems, with\n       applications to differential variability and differential\n       distribution testing","text":"Strbenac D., Mann, G.J., Ormerod, J.T., Yang, J. Y. H. (2015) ClassifyR: R package performance assessment classification applications transcriptomics, Bioinformatics.","code":""},{"path":"/reference/ClassifyResult-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Container for Storing Classification Results — ClassifyResult","title":"Container for Storing Classification Results — ClassifyResult","text":"Contains list models, table actual sample classes predicted classes, identifiers features selected fold permutation hold-classification, performance metrics error rates. class intended created user. created crossValidate, runTests runTest.","code":""},{"path":"/reference/ClassifyResult-class.html","id":"constructor","dir":"Reference","previous_headings":"","what":"Constructor","title":"Container for Storing Classification Results — ClassifyResult","text":"ClassifyResult(characteristics, originalNames, originalFeatures,               rankedFeatures, chosenFeatures, models, tunedParameters, predictions, actualOutcome, importance = NULL, modellingParams = NULL, finalModel = NULL) characteristics DataFrame describing characteristics classification done. First column must named \"charateristic\" second column must named \"value\". using wrapper functions feature selection classifiers package, function names automatically generated therefore necessary specify . originalNames sample names. originalFeatures feature names. Character vector DataFrame one row feature data set multiple kinds measurements set samples. chosenFeatures Features selected fold. Character vector data frame data set multiple kinds measurements set samples. models models fitted training data. tunedParameters Names tuning parameters value chosen parameter. predictions data frame containing sample IDs, predicted class risk information  cross-validation iteration prediction made. actualOutcome known class survival data sample. importance changes model performance selected variable excluded. modellingParams Stores object used defining model building enable future reuse. finalModel model built using sample future use. tuning parameters, popular value parameter cross-validation used.","code":""},{"path":"/reference/ClassifyResult-class.html","id":"summary","dir":"Reference","previous_headings":"","what":"Summary","title":"Container for Storing Classification Results — ClassifyResult","text":"result ClassifyResult object. show(result): Prints short summary result contains.","code":""},{"path":"/reference/ClassifyResult-class.html","id":"accessors","dir":"Reference","previous_headings":"","what":"Accessors","title":"Container for Storing Classification Results — ClassifyResult","text":"result ClassifyResult object. sampleNames(result) Returns vector sample names present data set. actualOutcome(result) Returns known outcome sample. models(result) list models fitted training. finalModel(result) deployable model fitted data use future data. chosenFeatureNames(result) list features selected training. predictions(result) Returns DataFrame columns test sample, cross-validation prediction information. performance(result) Returns list performance measures. empty calcCVperformance used. tunedParameters(result) Returns list tuned parameter values. cross-validation used, list large, stores chosen values every iteration. totalPredictions(result) single number representing total number. predictions made cross-validation procedure.","code":""},{"path":"/reference/ClassifyResult-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Container for Storing Classification Results — ClassifyResult","text":"Dario Strbenac","code":""},{"path":"/reference/ClassifyResult-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Container for Storing Classification Results — ClassifyResult","text":"","code":"#if(require(sparsediscrim))   #{     data(asthma)     classified <- crossValidate(measurements, classes, nRepeats = 5)     class(classified) #> [1] \"ClassifyResult\" #> attr(,\"package\") #> [1] \"ClassifyR\"   #}"},{"path":"/reference/CrossValParams-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for Cross-validation Specification — CrossValParams","title":"Parameters for Cross-validation Specification — CrossValParams","text":"Collects checks necessary parameters required cross-validation runTests.","code":""},{"path":"/reference/CrossValParams-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters for Cross-validation Specification — CrossValParams","text":"","code":"CrossValParams(   samplesSplits = c(\"Permute k-Fold\", \"Permute Percentage Split\", \"Leave-k-Out\",     \"k-Fold\"),   permutations = 100,   percentTest = 25,   folds = 5,   leave = 2,   tuneMode = c(\"Resubstitution\", \"Nested CV\", \"none\"),   adaptiveResamplingDelta = NULL,   parallelParams = bpparam() )"},{"path":"/reference/CrossValParams-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters for Cross-validation Specification — CrossValParams","text":"samplesSplits Default: \"Permute k-Fold\". character value specifying kind sample splitting . permutations Default: 100. Number times permute data set split training test sets. relevant samplesSplits either \"Permute k-Fold\" \"Permute Percentage Split\". percentTest percentage data set assign test set, remainder samples belonging training set. relevant samplesSplits \"Permute Percentage Split\". folds number approximately equal-sized folds partition samples . relevant samplesSplits \"Permute k-Fold\" \"k-Fold\". leave number samples generate possible combination use test set.  relevant samplesSplits \"Leave-k-\". set 1, traditional leave-one-cross-validation, sometimes written LOOCV. tuneMode Default: Resubstitution. scheme use selecting tuning parameters. adaptiveResamplingDelta Default: NULL. null, adaptive resampling training samples performed number difference consecutive iterations class probability risk samples must change less iterative process stop. 0.01 used original publication. parallelParams instance BiocParallelParam specifying kind parallelisation use. Default use two cores less total number cores computer , four cores, otherwise one core, default bpparam. make results fully reproducible, please choose specific back-end depending operating system also set RNGseed number.","code":""},{"path":"/reference/CrossValParams-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Parameters for Cross-validation Specification — CrossValParams","text":"Dario Strbenac","code":""},{"path":"/reference/CrossValParams-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters for Cross-validation Specification — CrossValParams","text":"","code":"CrossValParams() # Default is 100 permutations and 5 folds of each. #> An object of class \"CrossValParams\" #> Slot \"samplesSplits\": #> [1] \"Permute k-Fold\" #>  #> Slot \"permutations\": #> [1] 100 #>  #> Slot \"percentTest\": #> NULL #>  #> Slot \"folds\": #> [1] 5 #>  #> Slot \"leave\": #> NULL #>  #> Slot \"tuneMode\": #> [1] \"Resubstitution\" #>  #> Slot \"adaptiveResamplingDelta\": #> NULL #>  #> Slot \"parallelParams\": #> class: MulticoreParam #>   bpisup: FALSE; bpnworkers: 24; bptasks: 0; bpjobname: BPJOB #>   bplog: FALSE; bpthreshold: INFO; bpstopOnError: TRUE #>   bpRNGseed: ; bptimeout: NA; bpprogressbar: FALSE #>   bpexportglobals: TRUE; bpexportvariables: FALSE; bpforceGC: FALSE #>   bpfallback: TRUE #>   bplogdir: NA #>   bpresultdir: NA #>   cluster type: FORK #>    snow <- SnowParam(workers = 2, RNGseed = 999)   CrossValParams(\"Leave-k-Out\", leave = 2, parallelParams = snow) #> An object of class \"CrossValParams\" #> Slot \"samplesSplits\": #> [1] \"Leave-k-Out\" #>  #> Slot \"permutations\": #> NULL #>  #> Slot \"percentTest\": #> NULL #>  #> Slot \"folds\": #> NULL #>  #> Slot \"leave\": #> [1] 2 #>  #> Slot \"tuneMode\": #> [1] \"Resubstitution\" #>  #> Slot \"adaptiveResamplingDelta\": #> NULL #>  #> Slot \"parallelParams\": #> class: SnowParam #>   bpisup: FALSE; bpnworkers: 2; bptasks: 0; bpjobname: BPJOB #>   bplog: FALSE; bpthreshold: INFO; bpstopOnError: TRUE #>   bpRNGseed: 999; bptimeout: NA; bpprogressbar: FALSE #>   bpexportglobals: TRUE; bpexportvariables: TRUE; bpforceGC: FALSE #>   bpfallback: TRUE #>   bplogdir: NA #>   bpresultdir: NA #>   cluster type: SOCK #>    # Fully reproducible Leave-2-out cross-validation on 4 cores,   # even if feature selection or classifier use random sampling."},{"path":"/reference/FeatureSetCollection.html","id":null,"dir":"Reference","previous_headings":"","what":"Container for Storing A Collection of Sets — FeatureSetCollection-class","title":"Container for Storing A Collection of Sets — FeatureSetCollection-class","text":"container required storage format collection sets. Typically, elements set either set proteins (.e. character vector) perform particular biological process set binary interactions (.e. Two-column matrix feature identifiers).","code":""},{"path":"/reference/FeatureSetCollection.html","id":"constructor","dir":"Reference","previous_headings":"","what":"Constructor","title":"Container for Storing A Collection of Sets — FeatureSetCollection-class","text":"FeatureSetCollection(sets) sets named list. names list describe sets elements list specify features comprise sets.","code":""},{"path":"/reference/FeatureSetCollection.html","id":"summary","dir":"Reference","previous_headings":"","what":"Summary","title":"Container for Storing A Collection of Sets — FeatureSetCollection-class","text":"featureSets FeatureSetCollection object. show(featureSets): Prints short summary featureSets contains.length(featureSets): Prints many sets features .","code":""},{"path":"/reference/FeatureSetCollection.html","id":"subsetting","dir":"Reference","previous_headings":"","what":"Subsetting","title":"Container for Storing A Collection of Sets — FeatureSetCollection-class","text":"FeatureSetCollection may subsetted smaller set elements single set may extracted vector. featureSets FeatureSetCollection object. featureSets[:j]: Reduces object subset feature sets elements j collection.featureSets[[]]: Extract feature set identified . may numeric index character name feature set.","code":""},{"path":"/reference/FeatureSetCollection.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Container for Storing A Collection of Sets — FeatureSetCollection-class","text":"Dario Strbenac","code":""},{"path":"/reference/FeatureSetCollection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Container for Storing A Collection of Sets — FeatureSetCollection-class","text":"","code":"ontology <- list(c(\"SESN1\", \"PRDX1\", \"PRDX2\", \"PRDX3\", \"PRDX4\", \"PRDX5\", \"PRDX6\",                        \"LRRK2\", \"PARK7\"),                      c(\"ATP7A\", \"CCS\", \"NQO1\", \"PARK7\", \"SOD1\", \"SOD2\", \"SOD3\",                        \"SZT2\", \"TNF\"),                      c(\"AARS\", \"AIMP2\", \"CARS\", \"GARS\", \"KARS\", \"NARS\", \"NARS2\",                        \"LARS2\", \"NARS\", \"NARS2\", \"RGN\", \"UBA7\"),                      c(\"CRY1\", \"CRY2\", \"ONP1SW\", \"OPN4\", \"RGR\"),                      c(\"ESRRG\", \"RARA\", \"RARB\", \"RARG\", \"RXRA\", \"RXRB\", \"RXRG\"),                      c(\"CD36\", \"CD47\", \"F2\", \"SDC4\"),                      c(\"BUD31\", \"PARK7\", \"RWDD1\", \"TAF1\")                      )     names(ontology) <- c(\"Peroxiredoxin Activity\", \"Superoxide Dismutase Activity\",                          \"Ligase Activity\", \"Photoreceptor Activity\",                          \"Retinoic Acid Receptor Activity\",                          \"Thrombospondin Receptor Activity\",                          \"Regulation of Androgen Receptor Activity\")                               featureSets <- FeatureSetCollection(ontology)     featureSets #> An object of class 'FeatureSetCollection' consisting of 7 feature sets. #> Smallest set: 4 features. Largest set: 12 features.  #> Peroxiredoxin Activity: SESN1, PRDX1, PRDX2, PRDX3, PRDX4, ... #> Superoxide Dismutase Activity: ATP7A, CCS, NQO1, PARK7, SOD1, ... #> Ligase Activity: AARS, AIMP2, CARS, GARS, KARS, ... #>  ...                ... #> Retinoic Acid Receptor Activity: ESRRG, RARA, RARB, RARG, RXRA, ... #> Thrombospondin Receptor Activity: CD36, CD47, F2, SDC4 #> Regulation of Androgen Receptor Activity: BUD31, PARK7, RWDD1, TAF1     featureSets[3:5] #> An object of class 'FeatureSetCollection' consisting of 3 feature sets. #> Smallest set: 5 features. Largest set: 12 features.  #> Ligase Activity: AARS, AIMP2, CARS, GARS, KARS, ... #> Photoreceptor Activity: CRY1, CRY2, ONP1SW, OPN4, RGR #> Retinoic Acid Receptor Activity: ESRRG, RARA, RARB, RARG, RXRA, ...     featureSets[[\"Photoreceptor Activity\"]] #> [1] \"CRY1\"   \"CRY2\"   \"ONP1SW\" \"OPN4\"   \"RGR\"             subNetworks <- list(MAPK = matrix(c(\"NRAS\", \"NRAS\", \"NRAS\", \"BRAF\", \"MEK\",                                         \"ARAF\", \"BRAF\", \"CRAF\", \"MEK\", \"ERK\"), ncol = 2),                         P53 = matrix(c(\"ATM\", \"ATR\", \"ATR\", \"P53\",                                        \"CHK2\", \"CHK1\", \"P53\", \"MDM2\"), ncol = 2)                         )     networkSets <- FeatureSetCollection(subNetworks)                             networkSets #> An object of class 'FeatureSetCollection' consisting of 2 sets of binary interactions. #> Smallest set: 4 binary interactions. Largest set: 5 binary interactions.  #> MAPK: NRAS-ARAF, NRAS-BRAF, NRAS-CRAF, BRAF-MEK, MEK-ERK #> P53: ATM-CHK2, ATR-CHK1, ATR-P53, P53-MDM2"},{"path":"/reference/HuRI.html","id":null,"dir":"Reference","previous_headings":"","what":"Human Reference Interactome — HuRI","title":"Human Reference Interactome — HuRI","text":"collection 45783 pairs protein gene symbols, determined Human Reference Protein Interactome Mapping Project. Self-interactions removed.","code":""},{"path":"/reference/HuRI.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Human Reference Interactome — HuRI","text":"interactors Pairs object containing pair interacting proteins.","code":""},{"path":"/reference/HuRI.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Human Reference Interactome — HuRI","text":"Reference Map Human Binary Protein Interactome, Nature, 2020.  Webpage: http://www.interactome-atlas.org/download","code":""},{"path":"/reference/METABRICclinical.html","id":null,"dir":"Reference","previous_headings":"","what":"METABRIC Clinical Data — METABRICclinical","title":"METABRIC Clinical Data — METABRICclinical","text":"470 patients eight features.","code":""},{"path":"/reference/METABRICclinical.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"METABRIC Clinical Data — METABRICclinical","text":"clinical DataFrame containing clinical data.","code":""},{"path":"/reference/METABRICclinical.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"METABRIC Clinical Data — METABRICclinical","text":"Dynamics Breast Cancer Relapse Reveal Late-recurring ER-positive Genomic Subgroups, Nature, 2019.  Webpage: https://www.nature.com/articles/s43018-020-0026-6","code":""},{"path":"/reference/ModellingParams-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for Data Modelling Specification — ModellingParams","title":"Parameters for Data Modelling Specification — ModellingParams","text":"Collects checks necessary parameters required data modelling. Apart data transfomation needs done within cross-validation (e.g. subtracting observation training set mean), feature selection, model training prediction, container also stores setting class imbalance rebalancing.","code":""},{"path":"/reference/ModellingParams-class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameters for Data Modelling Specification — ModellingParams","text":"","code":"ModellingParams(   balancing = c(\"downsample\", \"upsample\", \"none\"),   transformParams = NULL,   selectParams = SelectParams(\"t-test\"),   trainParams = TrainParams(\"DLDA\"),   predictParams = PredictParams(\"DLDA\"),   doImportance = FALSE )"},{"path":"/reference/ModellingParams-class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters for Data Modelling Specification — ModellingParams","text":"balancing Default: \"downsample\". character value specifying kind class balancing , . transformParams Parameters used feature transformation inside C.V. specified TransformParams instance. Optional, can NULL. selectParams Parameters used feature selection specified SelectParams instance.  default, parameters selection based differences means numeric data. Optional, can NULL. trainParams Parameters model training specified TrainParams instance. default, uses diagonal LDA. predictParams Parameters model training specified PredictParams instance. default, uses diagonal LDA. doImportance Default: FALSE. Whether carry removal feature, one time, chosen retrain model predict test set, measure change performance metric. Can also set TRUE, required. Modelling run time noticeably longer.","code":""},{"path":"/reference/ModellingParams-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Parameters for Data Modelling Specification — ModellingParams","text":"Dario Strbenac","code":""},{"path":"/reference/ModellingParams-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters for Data Modelling Specification — ModellingParams","text":"","code":"#if(require(sparsediscrim))   #{      ModellingParams() # Default is differences in means selection and DLDA. #> An object of class \"ModellingParams\" #> Slot \"balancing\": #> [1] \"downsample\" #>  #> Slot \"transformParams\": #> NULL #>  #> Slot \"selectParams\": #> An object of class 'SelectParams'. #> Selection Name: Difference in Means. #>  #> Slot \"trainParams\": #> An object of class 'TrainParams'. #> Classifier Name: Diagonal LDA. #>  #> Slot \"predictParams\": #> An object of class 'PredictParams'. #>  #> Slot \"doImportance\": #> [1] FALSE #>       ModellingParams(selectParams = NULL, # No feature selection before training.                      trainParams = TrainParams(\"randomForest\"),                      predictParams = PredictParams(\"randomForest\")) #> An object of class \"ModellingParams\" #> Slot \"balancing\": #> [1] \"downsample\" #>  #> Slot \"transformParams\": #> NULL #>  #> Slot \"selectParams\": #> NULL #>  #> Slot \"trainParams\": #> An object of class 'TrainParams'. #> Classifier Name: Random Forest. #>  #> Slot \"predictParams\": #> An object of class 'PredictParams'. #>  #> Slot \"doImportance\": #> [1] FALSE #>    #}"},{"path":"/reference/PredictParams-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for Classifier Prediction — PredictParams","title":"Parameters for Classifier Prediction — PredictParams","text":"Collects function used making predictions associated parameters.","code":""},{"path":"/reference/PredictParams-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameters for Classifier Prediction — PredictParams","text":"function specified must return either factor vector class predictions, numeric vector scores second class, according levels class vector input data set, data frame two columns named class score.","code":""},{"path":"/reference/PredictParams-class.html","id":"constructor","dir":"Reference","previous_headings":"","what":"Constructor","title":"Parameters for Classifier Prediction — PredictParams","text":"PredictParams(predictor, characteristics = DataFrame(), intermediate = character(0), ...) Creates PredictParams object stores function class prediction, required, parameters function use. training function also makes predictions, must set NULL.","code":""},{"path":"/reference/PredictParams-class.html","id":"summary","dir":"Reference","previous_headings":"","what":"Summary","title":"Parameters for Classifier Prediction — PredictParams","text":"predictParams PredictParams object. show(predictParams): Prints short summary predictParams contains.","code":""},{"path":"/reference/PredictParams-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Parameters for Classifier Prediction — PredictParams","text":"Dario Strbenac","code":""},{"path":"/reference/PredictParams-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters for Classifier Prediction — PredictParams","text":"","code":"# For prediction by trained object created by DLDA training function. predictParams <- PredictParams(\"DLDA\")"},{"path":"/reference/ROCplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Receiver Operating Curve Graphs for Classification Results — ROCplot","title":"Plot Receiver Operating Curve Graphs for Classification Results — ROCplot","text":"Creates one ROC plot multiple ROC plots list ClassifyResult objects. One plot created data set two classes multiple plots created data set three classes.","code":""},{"path":"/reference/ROCplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Receiver Operating Curve Graphs for Classification Results — ROCplot","text":"","code":"# S4 method for ClassifyResult ROCplot(results, ...)  # S4 method for list ROCplot(   results,   mode = c(\"merge\", \"average\"),   interval = 95,   comparison = \"auto\",   lineColours = \"auto\",   lineWidth = 1,   fontSizes = c(24, 16, 12, 12, 12),   labelPositions = seq(0, 1, 0.2),   plotTitle = \"ROC\",   legendTitle = NULL,   xLabel = \"False Positive Rate\",   yLabel = \"True Positive Rate\",   showAUC = TRUE )"},{"path":"/reference/ROCplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Receiver Operating Curve Graphs for Classification Results — ROCplot","text":"results list ClassifyResult objects. ... Parameters used ClassifyResult method passed list method. mode Default: \"merge\". Whether merge predictions iterations cross-validation one set keep separate. Keeping separate cause separate ROC curves computed iteration confidence intervals drawn solid line averaged ROC curve. interval Default: 95 (percent). percent confidence interval draw around averaged ROC curve, mode \"\". comparison Default: \"auto\". aspect experimental design compare. Can characteristic results share. data set two classes, slot name factor levels used colouring lines. Otherwise, specifies variable used plot facetting. lineColours Default: \"auto\". vector colours different levels comparison parameter, three classes, classes. \"auto\", default colour palette automatically generated. lineWidth single number controlling thickness lines drawn. fontSizes vector length 5. first number size title.  second number size axes titles AUC text, part legend. third number size axes values. fourth number size legends' titles. fifth number font size legend labels. labelPositions Default: 0.0, 0.2, 0.4, 0.6, 0.8, 1.0. Locations put labels x y axes. plotTitle overall title plot. legendTitle default name used value NULL. Otherwise character name can provided. xLabel Label used x-axis false positive rate. yLabel Label used y-axis true positive rate. showAUC Logical. TRUE, AUC value result added legend text.","code":""},{"path":"/reference/ROCplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Receiver Operating Curve Graphs for Classification Results — ROCplot","text":"object class ggplot plot current graphics device, plot TRUE.","code":""},{"path":"/reference/ROCplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Receiver Operating Curve Graphs for Classification Results — ROCplot","text":"scores stored results higher sample likely class score associated . score class must column column name equal class name. cross-validated classification, predictions iterations considered simultaneously, calculate one curve per classification.","code":""},{"path":"/reference/ROCplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Receiver Operating Curve Graphs for Classification Results — ROCplot","text":"Dario Strbenac","code":""},{"path":"/reference/ROCplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Receiver Operating Curve Graphs for Classification Results — ROCplot","text":"","code":"predicted <- do.call(rbind, list(DataFrame(data.frame(sample = LETTERS[seq(1, 20, 2)],                                Healthy = c(0.89, 0.68, 0.53, 0.76, 0.13, 0.20, 0.60, 0.25, 0.10, 0.30),                                Cancer = c(0.11, 0.32, 0.47, 0.24, 0.87, 0.80, 0.40, 0.75, 0.90, 0.70),                                fold = 1)),                     DataFrame(sample = LETTERS[seq(2, 20, 2)],                                Healthy = c(0.45, 0.56, 0.33, 0.56, 0.65, 0.33, 0.20, 0.60, 0.40, 0.80),                                Cancer = c(0.55, 0.44, 0.67, 0.44, 0.35, 0.67, 0.80, 0.40, 0.60, 0.20),                                fold = 2)))   actual <- factor(c(rep(\"Healthy\", 10), rep(\"Cancer\", 10)), levels = c(\"Healthy\", \"Cancer\"))   result1 <- ClassifyResult(DataFrame(characteristic = c(\"Data Set\", \"Selection Name\", \"Classifier Name\", \"Cross-validation\"),                             value = c(\"Melanoma\", \"t-test\", \"Random Forest\", \"2-fold\")),                             LETTERS[1:20], paste(\"Gene\", LETTERS[1:10]), list(paste(\"Gene\", LETTERS[1:10]), paste(\"Gene\", LETTERS[c(5:1, 6:10)])),                             list(paste(\"Gene\", LETTERS[1:3]), paste(\"Gene\", LETTERS[1:5])),                             list(function(oracle){}), NULL, predicted, actual)      predicted[c(2, 6), \"Healthy\"] <- c(0.40, 0.60)   predicted[c(2, 6), \"Cancer\"] <- c(0.60, 0.40)   result2 <- ClassifyResult(DataFrame(characteristic = c(\"Data Set\", \"Selection Name\", \"Classifier Name\", \"Cross-validation\"),                                       value = c(\"Melanoma\", \"Bartlett Test\", \"Differential Variability\", \"2-fold\")),                             LETTERS[1:20], paste(\"Gene\", LETTERS[1:10]), list(paste(\"Gene\", LETTERS[1:10]), paste(\"Gene\", LETTERS[c(5:1, 6:10)])),                             list(paste(\"Gene\", LETTERS[1:3]), paste(\"Gene\", LETTERS[1:5])),                             list(function(oracle){}), NULL, predicted, actual)   ROCplot(list(result1, result2), plotTitle = \"Cancer ROC\")"},{"path":"/reference/SelectParams-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for Feature Selection — SelectParams","title":"Parameters for Feature Selection — SelectParams","text":"Collects checks necessary parameters required feature selection. Either one function specified list functions perform ensemble feature selection. empty constructor provided convenience.","code":""},{"path":"/reference/SelectParams-class.html","id":"constructor","dir":"Reference","previous_headings":"","what":"Constructor","title":"Parameters for Feature Selection — SelectParams","text":"SelectParams(featureRanking, characteristics = DataFrame(), minPresence = 1, intermediate = character(0),subsetToSelections = TRUE, tuneParams = list(nFeatures = seq(10, 100, 10), performanceType = \"Balanced Accuracy\"), ...) Creates SelectParams object stores function(s) selection parameters function use. featureRanking character keyword referring registered feature ranking function. See available valid keywords. characteristics DataFrame describing characteristics feature selection done. First column must named \"charateristic\" second column must named \"value\". using wrapper functions feature selection package, feature selection name automatically generated therefore necessary specify . minPresence list functions provided, many must feature selected used classification. 1 equivalent set union number length featureSelection equivalent set intersection. intermediate Character vector. Names variables created prior stages runTest need passed feature selection function. subsetToSelections Whether subset data table(s), feature selection done. tuneParams list specifying tuning parameters required feature selection. names list names parameters vectors values parameters try. possible combinations generated. Two elements named nFeatures performanceType mandatory, define performance metric used select features many top-ranked features try. ... named parameters used selection function. featureSelection list functions, must list lists, long featureSelection.","code":""},{"path":"/reference/SelectParams-class.html","id":"summary","dir":"Reference","previous_headings":"","what":"Summary","title":"Parameters for Feature Selection — SelectParams","text":"selectParams SelectParams object. show(SelectParams): Prints short summary selectParams contains.","code":""},{"path":"/reference/SelectParams-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Parameters for Feature Selection — SelectParams","text":"Dario Strbenac","code":""},{"path":"/reference/SelectParams-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters for Feature Selection — SelectParams","text":"","code":"#if(require(sparsediscrim))   #{     SelectParams(\"KS\") #> An object of class 'SelectParams'. #> Selection Name: Kolmogorov-Smirnov Test.          # Ensemble feature selection.     SelectParams(list(\"Bartlett\", \"Levene\")) #> An object of class 'SelectParams'. #> Ensemble Selection: Bartlett Test, Levene Test. #> Minimum Functions Selected By: 1   #}"},{"path":"/reference/TrainParams-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for Classifier Training — TrainParams","title":"Parameters for Classifier Training — TrainParams","text":"Collects checks necessary parameters required classifier training. empty constructor provided convenience.","code":""},{"path":"/reference/TrainParams-class.html","id":"constructor","dir":"Reference","previous_headings":"","what":"Constructor","title":"Parameters for Classifier Training — TrainParams","text":"TrainParams(classifier, balancing = c(\"downsample\", \"upsample\", \"none\"), characteristics = DataFrame(), intermediate = character(0), tuneParams = NULL, getFeatures = NULL, ...) Creates TrainParams object stores function classifier building parameters function use. classifier character keyword referring registered classifier. See available valid keywords. balancing Default: \"downsample\". keyword specifying handle class imbalance data sets categorical outcome. Valid values \"downsample\", \"upsample\" \"none\". characteristics DataFrame describing characteristics classifier used. First column must named \"charateristic\" second column must named \"value\". using wrapper functions classifiers package, classifier name automatically generated therefore necessary specify . intermediate Character vector. Names variables created prior stages runTest need passed classifier. tuneParams list specifying tuning parameters required feature selection. names list names parameters vectors values parameters try. possible combinations generated. getFeatures function may specified extracts selected features trained model. relevant using classifier feature selection within training (e.g. random forest). function must return list two vectors. first vector contains ranked features (empty training algorithm produce rankings) second vector contains selected features. ... named parameters used classifier.","code":""},{"path":"/reference/TrainParams-class.html","id":"summary","dir":"Reference","previous_headings":"","what":"Summary","title":"Parameters for Classifier Training — TrainParams","text":"trainParams TrainParams object. show(trainParams): Prints short summary trainParams contains.","code":""},{"path":"/reference/TrainParams-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Parameters for Classifier Training — TrainParams","text":"Dario Strbenac","code":""},{"path":"/reference/TrainParams-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters for Classifier Training — TrainParams","text":"","code":"#if(require(sparsediscrim))   trainParams <- TrainParams(\"DLDA\")"},{"path":"/reference/TransformParams-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for Data Transformation — TransformParams","title":"Parameters for Data Transformation — TransformParams","text":"Collects checks necessary parameters required transformation within CV.","code":""},{"path":"/reference/TransformParams-class.html","id":"constructor","dir":"Reference","previous_headings":"","what":"Constructor","title":"Parameters for Data Transformation — TransformParams","text":"TransformParams(transform, characteristics = DataFrame(), intermediate = character(0), ...) Creates TransformParams object stores function transformation parameters function use. transform character keyword referring registered transformation function. See available valid keywords. characteristics DataFrame describing characteristics data transformation done. First column must named \"charateristic\" second column must named \"value\". using wrapper functions data transformation package, data transformation name automatically generated therefore necessary specify . intermediate Character vector. Names variables created prior stages runTest need passed feature selection function. ... named parameters used transformation function.","code":""},{"path":"/reference/TransformParams-class.html","id":"summary","dir":"Reference","previous_headings":"","what":"Summary","title":"Parameters for Data Transformation — TransformParams","text":"transformParams TransformParams object. show(transformParams): Prints short summary transformParams contains.","code":""},{"path":"/reference/TransformParams-class.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Parameters for Data Transformation — TransformParams","text":"Dario Strbenac","code":""},{"path":"/reference/TransformParams-class.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameters for Data Transformation — TransformParams","text":"","code":"transformParams <- TransformParams(\"diffLoc\", location = \"median\")   # Subtract all values from training set median, to obtain absolute deviations."},{"path":"/reference/asthma.html","id":null,"dir":"Reference","previous_headings":"","what":"Asthma RNA Abundance and Patient Classes — asthma","title":"Asthma RNA Abundance and Patient Classes — asthma","text":"Data set consists matrix abundances 2000 variable gene expression measurements 190 samples factor vector classes samples.","code":""},{"path":"/reference/asthma.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Asthma RNA Abundance and Patient Classes — asthma","text":"measurements row sample column gene. classes factor vector values Yes, indicating particular person asthma .","code":""},{"path":"/reference/asthma.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Asthma RNA Abundance and Patient Classes — asthma","text":"Nasal Brush-based Classifier Asthma Identified Machine Learning Analysis Nasal RNA Sequence Data, Scientific Reports, 2018.  Webpage: http://www.nature.com/articles/s41598-018-27189-4","code":""},{"path":"/reference/available.html","id":null,"dir":"Reference","previous_headings":"","what":"List Available Feature Selection and Classification Approaches — available","title":"List Available Feature Selection and Classification Approaches — available","text":"Prints list keywords use crossValidate","code":""},{"path":"/reference/available.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Available Feature Selection and Classification Approaches — available","text":"","code":"available(what = c(\"classifier\", \"selectionMethod\", \"multiViewMethod\"))"},{"path":"/reference/available.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List Available Feature Selection and Classification Approaches — available","text":"Default: \"classifier\". Either \"classifier\", \"selectionMethod\" \"multiViewMethod\".","code":""},{"path":"/reference/available.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"List Available Feature Selection and Classification Approaches — available","text":"Dario Strbenac","code":""},{"path":"/reference/available.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List Available Feature Selection and Classification Approaches — available","text":"","code":"available() #>      classifier Keyword                                   Description #> 1          randomForest                                Random forest. #> 2                  DLDA        Diagonal Linear Discriminant Analysis. #> 3                   kNN                         k Nearest Neighbours. #> 4                   GLM                          Logistic regression. #> 5         elasticNetGLM       Elastic net GLM multinomial regression. #> 6                   SVM                       Support Vector Machine. #> 7                   NSC                   Nearest Shrunken Centroids. #> 8            naiveBayes Naive Bayes kernel feature voting classifier. #> 9       mixturesNormals Mixture of normals feature voting classifier. #> 10                CoxPH                     Cox proportional hazards. #> 11               CoxNet           Penalised Cox proportional hazards. #> 12 randomSurvivalForest                       Random survival forest. #> 13                  XGB                     Extreme gradient booster."},{"path":"/reference/calcPerformance.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Performance Calculations to a ClassifyResult Object or Calculate for a\nPair of Factor Vectors — calcExternalPerformance","title":"Add Performance Calculations to a ClassifyResult Object or Calculate for a\nPair of Factor Vectors — calcExternalPerformance","text":"calcExternalPerformance used, vector known classes vector predicted classes determined outside ClassifyR package, single metric value calculated. calcCVperformance used, annotates results calling crossValidate, runTests runTest one user-specified performance measures.","code":""},{"path":"/reference/calcPerformance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Performance Calculations to a ClassifyResult Object or Calculate for a\nPair of Factor Vectors — calcExternalPerformance","text":"","code":"# S4 method for factor,factor calcExternalPerformance(   actualOutcome,   predictedOutcome,   performanceTypes = \"auto\" )  # S4 method for Surv,numeric calcExternalPerformance(   actualOutcome,   predictedOutcome,   performanceTypes = \"auto\" )  # S4 method for factor,tabular calcExternalPerformance(   actualOutcome,   predictedOutcome,   performanceTypes = \"auto\" )  # S4 method for ClassifyResult calcCVperformance(result, performanceTypes = \"auto\")  performanceTable(   resultsList,   performanceTypes = \"auto\",   aggregate = c(\"median\", \"mean\") )"},{"path":"/reference/calcPerformance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Performance Calculations to a ClassifyResult Object or Calculate for a\nPair of Factor Vectors — calcExternalPerformance","text":"actualOutcome factor vector survival information specifying sample's known outcome. predictedOutcome factor vector survival information length actualOutcome specifying sample's predicted outcome. performanceTypes Default: \"auto\" character vector. \"auto\", Balanced Accuracy used classification task C-index time--event task. Must one following options: \"Error\": Ordinary error rate. \"Accuracy\": Ordinary accuracy. \"Balanced Error\": Balanced error rate. \"Balanced Accuracy\": Balanced accuracy. \"Sample Error\": Error rate sample data set. \"Sample Accuracy\": Accuracy sample data set. \"Micro Precision\": Sum number correct predictions         class, divided sum number samples class. \"Micro Recall\": Sum number correct predictions          class, divided sum number samples predicted         belonging class. \"Micro F1\": F1 score obtained calculating harmonic mean micro precision micro recall. \"Macro Precision\": Sum ratios number correct predictions class number samples class, divided number classes. \"Macro Recall\": Sum ratios number correct predictions class number samples predicted class, divided number classes. \"Macro F1\": F1 score obtained calculating harmonic mean macro precision macro recall. \"Matthews Correlation Coefficient\": Matthews Correlation Coefficient (MCC). score -1 1 indicating concordant predicted classes actual classes. defined two classes. \"AUC\": Area Curve. area ranging 0 1, ROC. \"C-index\": survival data, concordance index, models produce risk scores. Ranges 0 1. \"Sample C-index\": Per-individual C-index. result object class ClassifyResult. resultsList list modelling results. element must type ClassifyResult. aggregate Default: \"median\". Can also \"mean\". multiple values, repeated cross-validation, summarised single number using either mean median.","code":""},{"path":"/reference/calcPerformance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Performance Calculations to a ClassifyResult Object or Calculate for a\nPair of Factor Vectors — calcExternalPerformance","text":"calcCVperformance run, updated ClassifyResult object, new metric values performance slot. calcExternalPerformance run, performance metric value .","code":""},{"path":"/reference/calcPerformance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add Performance Calculations to a ClassifyResult Object or Calculate for a\nPair of Factor Vectors — calcExternalPerformance","text":"metrics except Matthews Correlation Coefficient suitable evaluating classification scenarios two classes reimplementations available Intel DAAL. crossValidate, runTests runTest run resampling mode, one performance measure produced every resampling. Otherwise, leave-k-mode used, predictions concatenated, one performance measure calculated classifications. \"Balanced Error\" calculates balanced error rate better suited class-imbalanced data sets ordinary error rate specified \"Error\". \"Sample Error\" calculates error rate sample individually. may help identify samples contributing overall error rate check confounding factors. Precision, recall F1 score micro macro summary versions. macro versions preferable metric good score substantial class imbalance classifier predicts samples belonging majority class.","code":""},{"path":"/reference/calcPerformance.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add Performance Calculations to a ClassifyResult Object or Calculate for a\nPair of Factor Vectors — calcExternalPerformance","text":"Dario Strbenac","code":""},{"path":"/reference/calcPerformance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Performance Calculations to a ClassifyResult Object or Calculate for a\nPair of Factor Vectors — calcExternalPerformance","text":"","code":"predictTable <- DataFrame(sample = paste(\"A\", 1:10, sep = ''),                             class = factor(sample(LETTERS[1:2], 50, replace = TRUE)))   actual <- factor(sample(LETTERS[1:2], 10, replace = TRUE))                                result <- ClassifyResult(DataFrame(characteristic = \"Data Set\", value = \"Example\"),                            paste(\"A\", 1:10, sep = ''), paste(\"Gene\", 1:50), list(paste(\"Gene\", 1:50), paste(\"Gene\", 1:50)), list(paste(\"Gene\", 1:5), paste(\"Gene\", 1:10)),                            list(function(oracle){}), NULL, predictTable, actual)   result <- calcCVperformance(result)    performance(result) #> $`Balanced Accuracy` #>    1  #> 0.38  #>"},{"path":"/reference/colCoxTests.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to perform fast or standard Cox proportional hazard model tests. — colCoxTests","title":"A function to perform fast or standard Cox proportional hazard model tests. — colCoxTests","text":"function perform fast standard Cox proportional hazard model tests.","code":""},{"path":"/reference/colCoxTests.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to perform fast or standard Cox proportional hazard model tests. — colCoxTests","text":"","code":"colCoxTests(measurements, outcome, option = c(\"fast\", \"slow\"), ...)"},{"path":"/reference/colCoxTests.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to perform fast or standard Cox proportional hazard model tests. — colCoxTests","text":"measurements matrix variables columns. outcome matrix first column time second column event. option Default: \"fast\". Whether use fast slow method. ... currently used.","code":""},{"path":"/reference/colCoxTests.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to perform fast or standard Cox proportional hazard model tests. — colCoxTests","text":"CrossValParams object","code":""},{"path":"/reference/colCoxTests.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A function to perform fast or standard Cox proportional hazard model tests. — colCoxTests","text":"","code":"data(asthma) time <- rpois(nrow(measurements), 100) status <- sample(c(0,1), nrow(measurements), replace = TRUE) outcome <- cbind(time, status) output <- colCoxTests(measurements, outcome, \"fast\")"},{"path":"/reference/crissCrossPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to plot the output of the crissCrossValidate function. — crissCrossPlot","title":"A function to plot the output of the crissCrossValidate function. — crissCrossPlot","text":"function designed give heatmap output crissCrossValidate function.","code":""},{"path":"/reference/crissCrossPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to plot the output of the crissCrossValidate function. — crissCrossPlot","text":"","code":"crissCrossPlot(crissCrossResult, includeValues = FALSE)"},{"path":"/reference/crissCrossPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to plot the output of the crissCrossValidate function. — crissCrossPlot","text":"crissCrossResult output crissCrossValidate function. includeValues TRUE, values matrix included plot.","code":""},{"path":"/reference/crissCrossPlot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A function to plot the output of the crissCrossValidate function. — crissCrossPlot","text":"Harry Robertson","code":""},{"path":"/reference/crissCrossValidate.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to perform pairwise cross validation — crissCrossValidate","title":"A function to perform pairwise cross validation — crissCrossValidate","text":"function designed perform cross-validation model prediction datasets pairwise manner.","code":""},{"path":"/reference/crissCrossValidate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to perform pairwise cross validation — crissCrossValidate","text":"","code":"crissCrossValidate(   measurements,   outcomes,   nFeatures = 20,   selectionMethod = \"auto\",   selectionOptimisation = \"Resubstitution\",   trainType = c(\"modelTrain\", \"modelTest\"),   performanceType = \"auto\",   doRandomFeatures = FALSE,   classifier = \"auto\",   nFolds = 5,   nRepeats = 20,   nCores = 1,   verbose = 0 )"},{"path":"/reference/crissCrossValidate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to perform pairwise cross validation — crissCrossValidate","text":"measurements list either DataFrame, data.frame matrix class measurements. outcomes list vectors respectively correspond outcomes samples measurements list. nFeatures number features used modelling. selectionMethod Default: \"auto\". character keyword feature algorithm used. \"auto\", t-test (two categories) / F-test (three categories) ranking top nFeatures optimisation done. Otherwise, ranking method per-feature Cox proportional hazards p-value. selectionOptimisation character \"Resubstitution\", \"Nested CV\" \"none\" specifying approach used optimise nFeatures. trainType Default: \"modelTrain\". keyword specifying whether fully trained model used make predictions test set feature identifiers chosen using training data set number training-predictions made cross-validation test set. performanceType Default: \"auto\". \"auto\", balanced accuracy classification C-index survival. Otherwise, one options described calcPerformance may otherwise specified. doRandomFeatures Default: FALSE. Whether perform random feature selection establish baseline performance. Either FALSE TRUE permitted values. classifier Default: \"auto\". character keyword modelling algorithm used. \"auto\", random forest used classification task Cox proportional hazards model survival task. nFolds numeric specifying number folds use cross-validation. nRepeats numeric specifying number repeats permutations use cross-validation. nCores numeric specifying number cores used user wants use parallelisation. verbose Default: 0. number 0 3 amount progress messages give.  higher number produce messages lower-level functions print messages.","code":""},{"path":"/reference/crissCrossValidate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to perform pairwise cross validation — crissCrossValidate","text":"list elements \"real\" matrix pairwise performance metrics using real feature selection, \"random\" doRandomFeatures TRUE metrics random selection \"params\" list parameters used execution function.","code":""},{"path":"/reference/crissCrossValidate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A function to perform pairwise cross validation — crissCrossValidate","text":"Harry Robertson","code":""},{"path":"/reference/crossValidate.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation to evaluate classification performance. — crossValidate","title":"Cross-validation to evaluate classification performance. — crossValidate","text":"function designed facilitate comparison classification methods using cross-validation, particularly multiple assays per biological unit. selection typical comparisons implemented. train function convenience method training one data set likewise predict predicting independent validation data set.","code":""},{"path":"/reference/crossValidate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation to evaluate classification performance. — crossValidate","text":"","code":"# S4 method for DataFrame crossValidate(   measurements,   outcome,   nFeatures = 20,   selectionMethod = \"auto\",   selectionOptimisation = \"Resubstitution\",   performanceType = \"auto\",   classifier = \"auto\",   multiViewMethod = \"none\",   assayCombinations = \"all\",   nFolds = 5,   nRepeats = 20,   nCores = 1,   characteristicsLabel = NULL,   extraParams = NULL,   verbose = 0 )  # S4 method for MultiAssayExperimentOrList crossValidate(   measurements,   outcome,   nFeatures = 20,   selectionMethod = \"auto\",   selectionOptimisation = \"Resubstitution\",   performanceType = \"auto\",   classifier = \"auto\",   multiViewMethod = \"none\",   assayCombinations = \"all\",   nFolds = 5,   nRepeats = 20,   nCores = 1,   characteristicsLabel = NULL,   extraParams = NULL )  # S4 method for data.frame crossValidate(   measurements,   outcome,   nFeatures = 20,   selectionMethod = \"auto\",   selectionOptimisation = \"Resubstitution\",   performanceType = \"auto\",   classifier = \"auto\",   multiViewMethod = \"none\",   assayCombinations = \"all\",   nFolds = 5,   nRepeats = 20,   nCores = 1,   characteristicsLabel = NULL,   extraParams = NULL )  # S4 method for matrix crossValidate(   measurements,   outcome,   nFeatures = 20,   selectionMethod = \"auto\",   selectionOptimisation = \"Resubstitution\",   performanceType = \"auto\",   classifier = \"auto\",   multiViewMethod = \"none\",   assayCombinations = \"all\",   nFolds = 5,   nRepeats = 20,   nCores = 1,   characteristicsLabel = NULL,   extraParams = NULL )  # S3 method for matrix train(x, outcomeTrain, ...)  # S3 method for data.frame train(x, outcomeTrain, ...)  # S3 method for DataFrame train(   x,   outcomeTrain,   selectionMethod = \"auto\",   nFeatures = 20,   classifier = \"auto\",   performanceType = \"auto\",   multiViewMethod = \"none\",   assayIDs = \"all\",   extraParams = NULL,   verbose = 0,   ... )  # S3 method for list train(x, outcomeTrain, ...)  # S3 method for MultiAssayExperiment train(x, outcome, ...)  # S3 method for trainedByClassifyR predict(object, newData, outcome, ...)"},{"path":"/reference/crossValidate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation to evaluate classification performance. — crossValidate","text":"measurements Either DataFrame, data.frame, matrix, MultiAssayExperiment  list basic tabular objects containing data. outcome vector class labels class factor length number samples measurements character vector length 1 containing column name measurements DataFrame. Surv object character vector length 2 3 specifying time event columns measurements survival outcome. measurements MultiAssayExperiment, column name(s) colData(measurements) representing outcome.  column names survival information, time must first column event status second. ... train predict functions, parameters used non-DataFrame signature functions passed DataFrame signature function. nFeatures number features used classification. single number, number features used comparisons assays. numeric vector optimised using selectionOptimisation. named vector names multiple assays,  different number features used assay. named list vectors, respective number features optimised .  Set NULL \"\" features used. selectionMethod Default: \"auto\". character vector feature selection methods compare. named character vector names corresponding different assays,  performing multiview classification, respective selection methods used assay. \"auto\", t-test (two categories) / F-test (three categories) ranking top nFeatures optimisation done. Otherwise, ranking method per-feature Cox proportional hazards p-value. \"none\" also valid value, meaning indepedent feature selection performed (implicit selection might still happen classifier). selectionOptimisation character \"Resubstitution\", \"Nested CV\" \"none\" specifying approach used optimise nFeatures. performanceType Performance metric optimise classifier tuning parameters. classifier Default: \"auto\". character vector classification methods compare. named character vector names corresponding different assays,  performing multiview classification, respective classification methods used assay. \"auto\", random forest used classification task Cox proportional hazards model survival task. multiViewMethod Default: \"none\". character vector specifying multiview method data integration approach use. See available(\"multiViewMethod\") possibilities. assayCombinations character vector list character vectors proposing assays , case list, combination assays use element vector assays combine. Special value \"\" means possible subsets assays. nFolds numeric specifying number folds use cross-validation. nRepeats numeric specifying number repeats permutations use cross-validation. nCores numeric specifying number cores used user wants use parallelisation. characteristicsLabel character specifying additional label cross-validation run. extraParams list parameters used overwrite default settings transformation, selection, model-building functions parameters passed data cleaning function. names list must one \"prepare\", \"select\", \"train\", \"predict\". remove one defaults (see article titled Parameter Tuning Presets crossValidate Customisation website), specify list element NULL. valid element names \"prepare\" list, see ?prepareData. verbose Default: 0. number 0 3 amount progress messages give.  higher number produce messages lower-level functions print messages. x measurements training samples. outcomeTrain train function, either factor vector classes, Surv object, character string, vector strings, containing column name(s) column(s) containing either classes time event information survival. column names survival information, time must first column event status second. assayIDs character vector assays train . Special value \"\" uses assays input object. object fitted model list models. newData predict function, object type matrix, data.frame DataFrame, list (matrices data frames) MultiAssayExperiment containing data make predictions either fitted model created train final model stored ClassifyResult object.","code":""},{"path":"/reference/crossValidate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation to evaluate classification performance. — crossValidate","text":"object class ClassifyResult","code":""},{"path":"/reference/crossValidate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation to evaluate classification performance. — crossValidate","text":"classifier can keyword implemented approaches shown available(). selectionMethod can keyword implemented approaches shown available(\"selectionMethod\"). multiViewMethod can keyword implemented approaches shown available(\"multiViewMethod\").","code":""},{"path":"/reference/crossValidate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation to evaluate classification performance. — crossValidate","text":"","code":"data(asthma)  # Compare randomForest and SVM classifiers. result <- crossValidate(measurements, classes, classifier = c(\"randomForest\", \"SVM\")) performancePlot(result) #> Warning: Balanced Accuracy not found in all elements of results. Calculating it now.    # Compare performance of different assays.  # First make a toy example assay with multiple data types. We'll randomly assign different features to be clinical, gene or protein. # set.seed(51773) # measurements <- DataFrame(measurements, check.names = FALSE) # mcols(measurements)$assay <- c(rep(\"clinical\",20),sample(c(\"gene\", \"protein\"), ncol(measurements)-20, replace = TRUE)) # mcols(measurements)$feature <- colnames(measurements)  # We'll use different nFeatures for each assay. We'll also use repeated cross-validation with 5 repeats for speed in the example. # set.seed(51773) #result <- crossValidate(measurements, classes, nFeatures = c(clinical = 5, gene = 20, protein = 30), classifier = \"randomForest\", nRepeats = 5) # performancePlot(result)  # Merge different assays. But we will only do this for two combinations. If assayCombinations is not specified it would attempt all combinations. # set.seed(51773) # resultMerge <- crossValidate(measurements, classes, assayCombinations = list(c(\"clinical\", \"protein\"), c(\"clinical\", \"gene\")), multiViewMethod = \"merge\", nRepeats = 5) # performancePlot(resultMerge)   # performancePlot(c(result, resultMerge))"},{"path":"/reference/distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Frequencies of Feature Selection and Sample-wise Classification Errors — distribution","title":"Get Frequencies of Feature Selection and Sample-wise Classification Errors — distribution","text":"two modes. aggregating feature selection results, function counts number times feature selected cross-validations. aggregating classification results, error rate sample calculated. useful identifying outlier samples difficult classify.","code":""},{"path":"/reference/distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Frequencies of Feature Selection and Sample-wise Classification Errors — distribution","text":"result object class ClassifyResult. ... parameters, colour fill, passed geom_histogram stat_density, depending value plotType. dataType Whether calculate sample-wise error rate number times feature selected. plotType Whether draw probability density curve histogram. summaryType Whether summarise feature selections percentage count. plot Whether draw plot frequency selection error rate. xMax Maximum data value show plot. fontSizes vector length 3. first number size title.  second number size axes titles. third number size axes values.","code":""},{"path":"/reference/distribution.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Frequencies of Feature Selection and Sample-wise Classification Errors — distribution","text":"dataType \"features\", vector long number features chosen least containing number times feature chosen cross validations percentage times chosen. dataType \"samples\", vector long number samples, containing cross-validation error rate sample. plot TRUE, plot also made current graphics device.","code":""},{"path":"/reference/distribution.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get Frequencies of Feature Selection and Sample-wise Classification Errors — distribution","text":"Dario Strbenac","code":""},{"path":"/reference/distribution.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Frequencies of Feature Selection and Sample-wise Classification Errors — distribution","text":"","code":"#if(require(sparsediscrim))   #{     data(asthma)     result <- crossValidate(measurements, classes, nRepeats = 5)     featureDistribution <- distribution(result, \"features\", summaryType = \"count\",                                         plotType = \"histogram\", binwidth = 1) #> Warning: Removed 2 rows containing missing values (`geom_bar()`).      print(head(featureDistribution)) #> allFeaturesText #>    ANKK1 ARHGAP39 C10orf95 C19orf51  C2orf55 C6orf108  #>        1       17       23       20        1        3    #}"},{"path":"/reference/edgesToHubNetworks.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a Two-column Matrix or Data Frame into a Hub Node List — edgesToHubNetworks","title":"Convert a Two-column Matrix or Data Frame into a Hub Node List — edgesToHubNetworks","text":"Interactions pairs features (typically protein-protein interaction, commonly abbreviated PPI, database) restructured named list. name element list feature element contains features interaction .","code":""},{"path":"/reference/edgesToHubNetworks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a Two-column Matrix or Data Frame into a Hub Node List — edgesToHubNetworks","text":"","code":"edgesToHubNetworks(edges, minCardinality = 5)"},{"path":"/reference/edgesToHubNetworks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a Two-column Matrix or Data Frame into a Hub Node List — edgesToHubNetworks","text":"edges two-column matrix data.frame row specifies known interaction betwen two interactors. feature X appears first column feature Y appears second, need feature Y appear first column feature X second. minCardinality integer specifying minimum number features associated hub feature present result.","code":""},{"path":"/reference/edgesToHubNetworks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a Two-column Matrix or Data Frame into a Hub Node List — edgesToHubNetworks","text":"object type FeatureSetCollection.","code":""},{"path":"/reference/edgesToHubNetworks.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert a Two-column Matrix or Data Frame into a Hub Node List — edgesToHubNetworks","text":"VAN: R package identifying biologically perturbed networks via differential variability analysis, Vivek Jayaswal, Sarah-Jane Schramm, Graham J Mann, Marc R Wilkins Yee Hwa Yang, 2010, BMC Research Notes, Volume 6 Article 430, https://bmcresnotes.biomedcentral.com/articles/10.1186/1756-0500-6-430.","code":""},{"path":"/reference/edgesToHubNetworks.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert a Two-column Matrix or Data Frame into a Hub Node List — edgesToHubNetworks","text":"Dario Strbenac","code":""},{"path":"/reference/edgesToHubNetworks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a Two-column Matrix or Data Frame into a Hub Node List — edgesToHubNetworks","text":"","code":"interactor <- c(\"MITF\", \"MITF\", \"MITF\", \"MITF\", \"MITF\", \"MITF\",                   \"KRAS\", \"KRAS\", \"KRAS\", \"KRAS\", \"KRAS\", \"KRAS\",                   \"PD-1\")   otherInteractor <- c(\"HINT1\", \"LEF1\", \"PSMD14\", \"PIAS3\", \"UBE2I\", \"PATZ1\",                        \"ARAF\", \"CALM1\", \"CALM2\", \"CALM3\", \"RAF1\", \"HNRNPC\",                        \"PD-L1\")   edges <- data.frame(interactor, otherInteractor, stringsAsFactors = FALSE)      edgesToHubNetworks(edges, minCardinality = 4) #> An object of class 'FeatureSetCollection' consisting of 2 feature sets. #> Smallest set: 6 features. Largest set: 6 features.  #> MITF: HINT1, LEF1, PSMD14, PIAS3, UBE2I, ... #> KRAS: ARAF, CALM1, CALM2, CALM3, RAF1, ..."},{"path":"/reference/featureSetSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform a Table of Feature Abundances into a Table of Feature Set\nAbundances. — featureSetSummary","title":"Transform a Table of Feature Abundances into a Table of Feature Set\nAbundances. — featureSetSummary","text":"Represents feature set mean median feature measurement feature set features belonging feature set.","code":""},{"path":"/reference/featureSetSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform a Table of Feature Abundances into a Table of Feature Set\nAbundances. — featureSetSummary","text":"","code":"# S4 method for matrix featureSetSummary(   measurements,   location = c(\"median\", \"mean\"),   featureSets,   minimumOverlapPercent = 80,   verbose = 3 )  # S4 method for DataFrame featureSetSummary(   measurements,   location = c(\"median\", \"mean\"),   featureSets,   minimumOverlapPercent = 80,   verbose = 3 )  # S4 method for MultiAssayExperiment featureSetSummary(   measurements,   target = NULL,   location = c(\"median\", \"mean\"),   featureSets,   minimumOverlapPercent = 80,   verbose = 3 )"},{"path":"/reference/featureSetSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform a Table of Feature Abundances into a Table of Feature Set\nAbundances. — featureSetSummary","text":"measurements Either matrix, DataFrame MultiAssayExperiment containing training data. matrix, rows samples, columns features. type DataFrame MultiAssayExperiment, data set subset features type numeric. location Default: median. type location summarise set features belonging feature set . featureSets object type FeatureSetCollection defines feature sets. minimumOverlapPercent minimum percentage overlapping features data set feature set defined featureSets feature set discarded anaylsis. verbose Default: 3. number 0 3 amount progress messages give.  function prints progress messages value 3. target input MultiAssayExperiment, specifies data set transformed. Can either integer index character string specifying name table. Must length 1.","code":""},{"path":"/reference/featureSetSummary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform a Table of Feature Abundances into a Table of Feature Set\nAbundances. — featureSetSummary","text":"class variable input variable measurements , individual features summarised feature sets. number samples remains unchanged, one dimension measurements altered.","code":""},{"path":"/reference/featureSetSummary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Transform a Table of Feature Abundances into a Table of Feature Set\nAbundances. — featureSetSummary","text":"feature transformation method unusual mean median feature feature set one sample may different another sample, whereas feature transformation methods result different features compared samples classification.","code":""},{"path":"/reference/featureSetSummary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Transform a Table of Feature Abundances into a Table of Feature Set\nAbundances. — featureSetSummary","text":"Network-based biomarkers enhance classical approaches prognostic gene expression signatures, Rebecca L Barter, Sarah-Jane Schramm, Graham J Mann Yee Hwa Yang, 2014, BMC Systems Biology, Volume 8 Supplement 4 Article S5, https://bmcsystbiol.biomedcentral.com/articles/10.1186/1752-0509-8-S4-S5.","code":""},{"path":"/reference/featureSetSummary.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Transform a Table of Feature Abundances into a Table of Feature Set\nAbundances. — featureSetSummary","text":"Dario Strbenac","code":""},{"path":"/reference/featureSetSummary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform a Table of Feature Abundances into a Table of Feature Set\nAbundances. — featureSetSummary","text":"","code":"sets <- list(Adhesion = c(\"Gene 1\", \"Gene 2\", \"Gene 3\"),                `Cell Cycle` = c(\"Gene 8\", \"Gene 9\", \"Gene 10\"))   featureSets <- FeatureSetCollection(sets)      # Adhesion genes have a median gene difference between classes.   genesMatrix <- matrix(c(rnorm(5, 9, 0.3), rnorm(5, 7, 0.3), rnorm(5, 8, 0.3),                         rnorm(5, 6, 0.3), rnorm(10, 7, 0.3), rnorm(70, 5, 0.1)),                         nrow = 10)   rownames(genesMatrix) <- paste(\"Patient\", 1:10)   colnames(genesMatrix) <- paste(\"Gene\", 1:10)   classes <- factor(rep(c(\"Poor\", \"Good\"), each = 5)) # But not used for transformation.      featureSetSummary(genesMatrix, featureSets = featureSets) #> Summarising features to feature sets. #>            Adhesion Cell Cycle #> Patient 1  7.735844   4.923781 #> Patient 2  8.053842   4.980945 #> Patient 3  7.829585   5.012342 #> Patient 4  8.031012   4.973666 #> Patient 5  7.538554   4.933802 #> Patient 6  6.881841   4.996924 #> Patient 7  6.848896   4.909489 #> Patient 8  6.786027   4.983288 #> Patient 9  6.473840   5.158214 #> Patient 10 6.827406   4.991137"},{"path":"/reference/generateCrossValParams.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to generate a CrossValParams object — generateCrossValParams","title":"A function to generate a CrossValParams object — generateCrossValParams","text":"function generate CrossValParams object","code":""},{"path":"/reference/generateCrossValParams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to generate a CrossValParams object — generateCrossValParams","text":"","code":"generateCrossValParams(nRepeats, nFolds, nCores, selectionOptimisation)"},{"path":"/reference/generateCrossValParams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to generate a CrossValParams object — generateCrossValParams","text":"nRepeats numeric specifying number repeats permutations use cross-validation. nFolds numeric specifying number folds use cross-validation. nCores numeric specifying number cores used user wants use parallelisation. selectionOptimisation character \"Resubstitution\", \"Nested CV\" \"none\" specifying approach used optimise nFeatures.","code":""},{"path":"/reference/generateCrossValParams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to generate a CrossValParams object — generateCrossValParams","text":"CrossValParams object","code":""},{"path":"/reference/generateCrossValParams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A function to generate a CrossValParams object — generateCrossValParams","text":"","code":"CVparams <- generateCrossValParams(nRepeats = 20, nFolds = 5, nCores = 8, selectionOptimisation = \"none\") #> Error in generateCrossValParams(nRepeats = 20, nFolds = 5, nCores = 8,     selectionOptimisation = \"none\"): could not find function \"generateCrossValParams\""},{"path":"/reference/generateModellingParams.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to generate a ModellingParams object — generateModellingParams","title":"A function to generate a ModellingParams object — generateModellingParams","text":"function generate ModellingParams object","code":""},{"path":"/reference/generateModellingParams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to generate a ModellingParams object — generateModellingParams","text":"","code":"generateModellingParams(   assayIDs,   measurements,   nFeatures,   selectionMethod,   selectionOptimisation,   performanceType = \"auto\",   classifier,   multiViewMethod = \"none\" )"},{"path":"/reference/generateModellingParams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to generate a ModellingParams object — generateModellingParams","text":"assayIDs vector data set identifiers long number data sets. measurements Either DataFrame, data.frame, matrix, MultiAssayExperiment  list objects containing data. nFeatures number features used classification. single number, number features used comparisons assays. numeric vector optimised using selectionOptimisation. named vector names multiple assays,  different number features used assay. named list vectors, respective number features optimised .  Set NULL \"\" features used. selectionMethod Default: \"auto\". character vector feature selection methods compare. named character vector names corresponding different assays,  performing multiview classification, respective classification methods used assay. \"auto\" t-test (two categories) / F-test (three categories) ranking top nFeatures optimisation done. Otherwise, ranking method per-feature Cox proportional hazards p-value. selectionOptimisation character \"Resubstitution\", \"Nested CV\" \"none\" specifying approach used optimise nFeatures. performanceType Performance metric optimise classifier tuning parameters. classifier Default: \"auto\". character vector classification methods compare. named character vector names corresponding different assays,  performing multiview classification, respective classification methods used assay. \"auto\", random forest used classification task Cox proportional hazards model survival task. multiViewMethod character vector specifying multiview method data integration approach use.","code":""},{"path":"/reference/generateModellingParams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to generate a ModellingParams object — generateModellingParams","text":"ModellingParams object","code":""},{"path":"/reference/generateModellingParams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A function to generate a ModellingParams object — generateModellingParams","text":"","code":"data(asthma) # First make a toy example assay with multiple data types. We'll randomly assign different features to be clinical, gene or protein. set.seed(51773) measurements <- DataFrame(measurements, check.names = FALSE)  mcols(measurements)$assay <- c(rep(\"clinical\",20),sample(c(\"gene\", \"protein\"), ncol(measurements)-20, replace = TRUE)) mcols(measurements)$feature <- colnames(measurements) modellingParams <- generateModellingParams(assayIDs = c(\"clinical\", \"gene\", \"protein\"),                                           measurements = measurements,                                            nFeatures = list(clinical = 10, gene = 10, protein = 10),                                           selectionMethod = list(clinical = \"t-test\", gene = \"t-test\", protein = \"t-test\"),                                           selectionOptimisation = \"none\",                                           classifier = \"randomForest\",                                           multiViewMethod = \"merge\") #> Error in generateModellingParams(assayIDs = c(\"clinical\", \"gene\", \"protein\"),     measurements = measurements, nFeatures = list(clinical = 10,         gene = 10, protein = 10), selectionMethod = list(clinical = \"t-test\",         gene = \"t-test\", protein = \"t-test\"), selectionOptimisation = \"none\",     classifier = \"randomForest\", multiViewMethod = \"merge\"): could not find function \"generateModellingParams\""},{"path":"/reference/interactorDifferences.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Individual Features into Differences Between Binary Interactors\nBased on Known Sub-networks — interactorDifferences","title":"Convert Individual Features into Differences Between Binary Interactors\nBased on Known Sub-networks — interactorDifferences","text":"conversion useful creating meta-feature table classifier training prediction based sub-networks selected based differential correlation classes.","code":""},{"path":"/reference/interactorDifferences.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Individual Features into Differences Between Binary Interactors\nBased on Known Sub-networks — interactorDifferences","text":"","code":"# S4 method for matrix interactorDifferences(measurements, ...)  # S4 method for DataFrame interactorDifferences(   measurements,   featurePairs = NULL,   absolute = FALSE,   verbose = 3 )  # S4 method for MultiAssayExperiment interactorDifferences(measurements, useFeatures = \"all\", ...)"},{"path":"/reference/interactorDifferences.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Individual Features into Differences Between Binary Interactors\nBased on Known Sub-networks — interactorDifferences","text":"measurements Either matrix, DataFrame MultiAssayExperiment containing training data.  matrix, rows samples, columns features. ... Variables used matrix MultiAssayExperiment method passed used DataFrame method. featurePairs object type Pairs. absolute TRUE, absolute values differences returned. verbose Default: 3. number 0 3 amount progress messages give.  function prints progress messages value 3. useFeatures measurements MultiAssayExperiment, \"\" two-column table features use. table, first column must assay names second column must feature names found assay. \"clinical\" also valid assay name refers clinical data table.","code":""},{"path":"/reference/interactorDifferences.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Individual Features into Differences Between Binary Interactors\nBased on Known Sub-networks — interactorDifferences","text":"object class DataFrame one column interactor pair difference one row sample. Additionally, mcols(resultTable) prodvides DataFrame column named \"original\" containing name sub-network meta-feature belongs .","code":""},{"path":"/reference/interactorDifferences.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert Individual Features into Differences Between Binary Interactors\nBased on Known Sub-networks — interactorDifferences","text":"pairs features known interact specified networkSets.","code":""},{"path":"/reference/interactorDifferences.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert Individual Features into Differences Between Binary Interactors\nBased on Known Sub-networks — interactorDifferences","text":"Dynamic modularity protein interaction networks predicts breast cancer outcome, Ian W Taylor, Rune Linding, David Warde-Farley, Yongmei Liu, Catia Pesquita, Daniel Faria, Shelley Bull, Tony Pawson, Quaid Morris Jeffrey L Wrana, 2009, Nature Biotechnology, Volume 27 Issue 2, https://www.nature.com/articles/nbt.1522.","code":""},{"path":"/reference/interactorDifferences.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert Individual Features into Differences Between Binary Interactors\nBased on Known Sub-networks — interactorDifferences","text":"Dario Strbenac","code":""},{"path":"/reference/interactorDifferences.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Individual Features into Differences Between Binary Interactors\nBased on Known Sub-networks — interactorDifferences","text":"","code":"pairs <- Pairs(rep(c('A', 'G'), each = 3), c('B', 'C', 'D', 'H', 'I', 'J'))                               # Consistent differences for interactors of A.                                              measurements <- matrix(c(5.7, 10.1, 6.9, 7.7, 8.8, 9.1, 11.2, 6.4, 7.0, 5.5,                            3.6, 7.6, 4.0, 4.4, 5.8, 6.2, 8.1, 3.7, 4.4, 2.1,                            8.5, 13.0, 9.9, 10.0, 10.3, 11.9, 13.8, 9.9, 10.7, 8.5,                            8.1, 10.6, 7.4, 10.7, 10.8, 11.1, 13.3, 9.7, 11.0, 9.1,                            round(rnorm(60, 8, 0.3), 1)), nrow = 10)                             rownames(measurements) <- paste(\"Patient\", 1:10)   colnames(measurements) <- LETTERS[1:10]      interactorDifferences(measurements, pairs) #> Calculating differences between the specified interactors. #> DataFrame with 10 rows and 6 columns #>                B - A     C - A     D - A     H - G     I - G     J - G #>            <numeric> <numeric> <numeric> <numeric> <numeric> <numeric> #> Patient 1       -2.1       2.8       2.4       0.1      -0.6      -0.7 #> Patient 2       -2.5       2.9       0.5      -0.7      -0.6      -0.9 #> Patient 3       -2.9       3.0       0.5      -0.5      -0.2       0.3 #> Patient 4       -3.3       2.3       3.0      -0.9       0.2      -0.4 #> Patient 5       -3.0       1.5       2.0      -0.2       0.1       0.3 #> Patient 6       -2.9       2.8       2.0       0.3       0.6      -0.2 #> Patient 7       -3.1       2.6       2.1       0.4      -0.4      -0.2 #> Patient 8       -2.7       3.5       3.3       0.4       0.4       0.0 #> Patient 9       -2.6       3.7       4.0       1.0       0.5       0.4 #> Patient 10      -3.4       3.0       3.6      -0.3      -0.4      -0.1"},{"path":"/reference/performancePlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Performance Measures for Various Classifications — performancePlot","title":"Plot Performance Measures for Various Classifications — performancePlot","text":"Draws graphical summary particular performance measure list classifications","code":""},{"path":"/reference/performancePlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Performance Measures for Various Classifications — performancePlot","text":"","code":"# S4 method for ClassifyResult performancePlot(results, ...)  # S4 method for list performancePlot(   results,   metric = \"auto\",   characteristicsList = list(x = \"auto\"),   aggregate = character(),   coloursList = list(),   orderingList = list(),   densityStyle = c(\"box\", \"violin\"),   yLimits = NULL,   fontSizes = c(24, 16, 12, 12),   title = NULL,   margin = grid::unit(c(1, 1, 1, 1), \"lines\"),   rotate90 = FALSE,   showLegend = TRUE )"},{"path":"/reference/performancePlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Performance Measures for Various Classifications — performancePlot","text":"results list ClassifyResult objects. ... used end user. metric Default: \"auto\". name performance measure \"auto\". results classification balanced accuracy displayed. Otherwise, results survival risk predictions C-index displayed. one names printed Performance Measures field ClassifyResult object printed, none stored, performance metric calculated automatically. characteristicsList named list characteristics. element's name must one \"x\", \"row\", \"column\", \"fillColour\", \"fillLine\". value element must characteristic name, stored \"characteristic\" column results' characteristics table. \"x\" mandatory. \"auto\" default, identify characteristic unique value element results. aggregate character vector levels characteristicsList['x'] aggregate single number taking mean. particularly meaningful cross-validation leave-k-, k small. coloursList named list plot aspects colours aspects. elements mandatory. specified, list element's name must either \"fillColours\" \"lineColours\". characteristic associated fill line characteristicsList list empty, palette colours automatically chosen. orderingList optional named list. variables specified characteristicsList can name element list value element order factors presented , case alphabetical sorting undesirable. Special values \"performanceAscending\" \"performanceDescending\" indicate order levels computed based median performance value characteristic sorted ascending descending order. densityStyle Default: \"box\". Either \"violin\" violin plot \"box\" box plot. yLimits minimum maximum value performance metric plot. fontSizes vector length 4. first number size title.  second number size axes titles. third number size axes values. fourth number font size titles grouped plots, produced. words, rowVariable columnVariable NULL. title overall title plot. margin margin around plot. rotate90 Logical. TRUE, plot horizontal. showLegend TRUE, legend plotted next plot. FALSE, hidden.","code":""},{"path":"/reference/performancePlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Performance Measures for Various Classifications — performancePlot","text":"object class ggplot plot current graphics device, plot TRUE.","code":""},{"path":"/reference/performancePlot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Performance Measures for Various Classifications — performancePlot","text":"multiple values performance measure single result object, plotted violin plot, unless aggregate TRUE, case predictions single result object considered simultaneously, one performance number calculated, barchart plotted.","code":""},{"path":"/reference/performancePlot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Performance Measures for Various Classifications — performancePlot","text":"Dario Strbenac","code":""},{"path":"/reference/performancePlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Performance Measures for Various Classifications — performancePlot","text":"","code":"predicted <- DataFrame(sample = sample(LETTERS[1:10], 80, replace = TRUE),                          permutation = rep(1:2, each = 40),                          class = factor(rep(c(\"Healthy\", \"Cancer\"), 40)))   actual <- factor(rep(c(\"Healthy\", \"Cancer\"), each = 5))   result1 <- ClassifyResult(DataFrame(characteristic = c(\"Data Set\", \"Selection Name\", \"Classifier Name\",                                                          \"Cross-validation\"),                             value = c(\"Example\", \"t-test\", \"Differential Expression\", \"2 Permutations, 2 Folds\")),                             LETTERS[1:10], paste(\"Gene\", 1:100), list(paste(\"Gene\", 1:100), paste(\"Gene\", c(10:1, 11:100)), paste(\"Gene\", 1:100), paste(\"Gene\", 1:100)),                             list(paste(\"Gene\", 1:3), paste(\"Gene\", c(2, 5, 6)), paste(\"Gene\", 1:4), paste(\"Gene\", 5:8)),                             list(function(oracle){}), NULL, predicted, actual)   result1 <- calcCVperformance(result1, \"Macro F1\")    predicted <- DataFrame(sample = sample(LETTERS[1:10], 80, replace = TRUE),                           permutation = rep(1:2, each = 40),                           class = factor(rep(c(\"Healthy\", \"Cancer\"), 40)))                                   result2 <- ClassifyResult(DataFrame(characteristic = c(\"Data Set\", \"Selection Name\", \"Classifier Name\",                                                          \"Cross-validation\"),                             value = c(\"Example\", \"Bartlett Test\", \"Differential Variability\", \"2 Permutations, 2 Folds\")),                             LETTERS[1:10], paste(\"Gene\", 1:100), list(paste(\"Gene\", 1:100), paste(\"Gene\", c(10:1, 11:100)), paste(\"Gene\", 1:100), paste(\"Gene\", 1:100)),                             list(c(1:3), c(4:6), c(1, 6, 7, 9), c(5:8)),                             list(function(oracle){}), NULL, predicted, actual)   result2 <- calcCVperformance(result2, \"Macro F1\")      performancePlot(list(result1, result2), metric = \"Macro F1\",                   title = \"Comparison\")"},{"path":"/reference/plotFeatureClasses.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Density, Scatterplot, Parallel Plot or Bar Chart for Features By Class — plotFeatureClasses","title":"Plot Density, Scatterplot, Parallel Plot or Bar Chart for Features By Class — plotFeatureClasses","text":"Allows visualisation measurements data set. useFeatures type Pairs, parallel plot automatically drawn. single categorical variable, bar chart automatically drawn.","code":""},{"path":"/reference/plotFeatureClasses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Density, Scatterplot, Parallel Plot or Bar Chart for Features By Class — plotFeatureClasses","text":"","code":"# S4 method for matrix plotFeatureClasses(measurements, ...)  # S4 method for DataFrame plotFeatureClasses(   measurements,   classes,   useFeatures,   groupBy = NULL,   groupingName = NULL,   whichNumericFeaturePlots = c(\"both\", \"density\", \"stripchart\"),   measurementLimits = NULL,   lineWidth = 1,   dotBinWidth = 1,   xAxisLabel = NULL,   yAxisLabels = c(\"Density\", \"Classes\"),   showXtickLabels = TRUE,   showYtickLabels = TRUE,   xLabelPositions = \"auto\",   yLabelPositions = \"auto\",   fontSizes = c(24, 16, 12, 12, 12),   colours = c(\"#3F48CC\", \"#880015\"),   showAssayName = TRUE,   plot = TRUE )  # S4 method for MultiAssayExperiment plotFeatureClasses(   measurements,   useFeatures,   classesColumn,   groupBy = NULL,   groupingName = NULL,   showAssayName = TRUE,   ... )"},{"path":"/reference/plotFeatureClasses.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Density, Scatterplot, Parallel Plot or Bar Chart for Features By Class — plotFeatureClasses","text":"measurements matrix, DataFrame MultiAssayExperiment object containing data.  matrix, rows features columns samples.  column name \"class\" must present DataFrame stored colData slot. ... Unused variables three top-level methods passed internal method generates plot(s). classes Either vector class labels class factor measurements class DataFrame character vector length 1 containing column name measurement also permitted. used measurements MultiAssayExperiment object. useFeatures measurements matrix DataFrame, vector numeric character indices feature identifiers corresponding feature(s) plotted. measurements MultiAssayExperiment, DataFrame 2 columns must specified. first column contains names assays second contains names variables, thus row unambiguously specifies variable plotted. groupBy measurements DataFrame, character vector length 1, contains name categorical feature, may specified.  measurements MultiAssayExperiment, character vector length 2, contains name data table first element name categorical feature second element, may specified.  Additionally, value \"clinical\" may used refer column annotation stored colData slot MultiAssayExperiment object. density plot additional lines different line types category. strip chart plot separate strip chart created category charts drawn single column graphics device. parallel plot bar chart plot similarly laid . groupingName label grouping variable used plots. whichNumericFeaturePlots feature single feature numeric measurements, option specifies types plot(s) draw. default value \"\", draws density plot also stip chart density plot. options \"density\" drawing density plot \"stripchart\" drawing strip chart. measurementLimits minimum maximum expression values plot. Default: NULL.  default, limits automatically computed data values. lineWidth Numeric value alters line thickness density plots. Default: 1. dotBinWidth Numeric value alters diameter dots strip chart. Default: 1. xAxisLabel axis label plot's horizontal axis. Default: NULL. yAxisLabels character vector length 1 2. feature's measurements numeric whichNumericFeaturePlots value \"\", first value y-axis label density plot second value y-axis label strip chart. Otherwise, feature's measurements numeric one plot drawn, character vector length 1 specifies y-axis label particular plot. Ignored feature's measurements categorical. showXtickLabels Logical. Default: TRUE. set FALSE, x-axis labels hidden. showYtickLabels Logical. Default: TRUE. set FALSE, y-axis labels hidden. xLabelPositions Either \"auto\" vector values. positions labels x-axis.  \"auto\", placement labels automatically calculated. yLabelPositions Either \"auto\" vector values. positions labels y-axis.  \"auto\", placement labels automatically calculated. fontSizes vector length 5. first number size title.  second number size axes titles. third number size axes values. fourth number size legends' titles. fifth number font size legend labels. colours colours plot data class . length vector must long distinct number classes data set. showAssayName Logical. Default: TRUE. TRUE data MultiAssayExperiment object, name table feature stored added plot title. plot Logical. Default: TRUE. TRUE, plot produced current graphics device. classesColumn measurementsTrain MultiAssayExperiment, names class column table extracted colData(multiAssayExperiment) contains sample's outcome use prediction.","code":""},{"path":"/reference/plotFeatureClasses.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Density, Scatterplot, Parallel Plot or Bar Chart for Features By Class — plotFeatureClasses","text":"Plots created current graphics device list plot objects invisibly returned. classes plot object determined based type data plotted number plots per feature generated. plotted variable discrete variable numeric one plot type specified, list element object class ggplot. Otherwise, variable numeric density stripchart plot types made, list element object class TableGrob. Settling lineWidth dotBinWidth value result density plot strip chart elements size. manual experimentation required get similarly sized plot elements.","code":""},{"path":"/reference/plotFeatureClasses.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Density, Scatterplot, Parallel Plot or Bar Chart for Features By Class — plotFeatureClasses","text":"Dario Strbenac","code":""},{"path":"/reference/plotFeatureClasses.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Density, Scatterplot, Parallel Plot or Bar Chart for Features By Class — plotFeatureClasses","text":"","code":"# First 25 samples and first 5 genes are mixtures of two normals. Last 25 samples are   # one normal.   genesMatrix <- sapply(1:15, function(geneColumn) c(rnorm(5, 5, 1)))   genesMatrix <- cbind(genesMatrix, sapply(1:10, function(geneColumn) c(rnorm(5, 15, 1))))   genesMatrix <- cbind(genesMatrix, sapply(1:25, function(geneColumn) c(rnorm(5, 9, 2))))   genesMatrix <- rbind(genesMatrix, sapply(1:50, function(geneColumn) rnorm(95, 9, 3)))   genesMatrix <- t(genesMatrix)   rownames(genesMatrix) <- paste(\"Sample\", 1:50)   colnames(genesMatrix) <- paste(\"Gene\", 1:100)   classes <- factor(rep(c(\"Poor\", \"Good\"), each = 25), levels = c(\"Good\", \"Poor\"))   plotFeatureClasses(genesMatrix, classes, useFeatures = \"Gene 4\",                      xAxisLabel = bquote(log[2]*'(expression)'), dotBinWidth = 0.5)                                                   infectionResults <- c(rep(c(\"No\", \"Yes\"), c(20, 5)), rep(c(\"No\", \"Yes\"), c(5, 20)))   genders <- factor(rep(c(\"Male\", \"Female\"), each = 10, length.out = 50))   clinicalData <- DataFrame(Gender = genders, Sugar = runif(50, 4, 10),                               Infection = factor(infectionResults, levels = c(\"No\", \"Yes\")),                             row.names = rownames(genesMatrix))   plotFeatureClasses(clinicalData, classes, useFeatures = \"Infection\")    plotFeatureClasses(clinicalData, classes, useFeatures = \"Infection\", groupBy = \"Gender\")      genesMatrix <- t(genesMatrix) # MultiAssayExperiment needs features in rows.   dataContainer <- MultiAssayExperiment(list(RNA = genesMatrix),                                         colData = cbind(clinicalData, class = classes))   targetFeatures <- DataFrame(assay = \"RNA\", feature = \"Gene 50\")                                        plotFeatureClasses(dataContainer, useFeatures = targetFeatures, classesColumn = \"class\",                      groupBy = c(\"clinical\", \"Gender\"), # Table name, feature name.                      xAxisLabel = bquote(log[2]*'(expression)'), dotBinWidth = 0.5)"},{"path":"/reference/precisionPathways.html","id":null,"dir":"Reference","previous_headings":"","what":"Precision Pathways for Sample Prediction Based on Prediction Confidence. — precisionPathwaysTrain","title":"Precision Pathways for Sample Prediction Based on Prediction Confidence. — precisionPathwaysTrain","text":"Precision pathways allows evaluation various permutations multiomics multiview data. Samples predicted particular assay consistently predicted particular class cross-validation. Otherwise, passed onto subsequent assays/tiers prediction. Balanced accuracy used evaluate overall prediction performance sample-specific accuracy individual-level evaluation.","code":""},{"path":"/reference/precisionPathways.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Precision Pathways for Sample Prediction Based on Prediction Confidence. — precisionPathwaysTrain","text":"","code":"# S4 method for MultiAssayExperimentOrList precisionPathwaysTrain(   measurements,   class,   useFeatures = NULL,   maxMissingProp = 0,   topNvariance = NULL,   fixedAssays = \"clinical\",   confidenceCutoff = 0.8,   minAssaySamples = 10,   nFeatures = 20,   selectionMethod = setNames(c(\"none\", rep(\"t-test\", length(measurements))),     c(\"clinical\", names(measurements))),   classifier = setNames(c(\"elasticNetGLM\", rep(\"randomForest\", length(measurements))),     c(\"clinical\", names(measurements))),   nFolds = 5,   nRepeats = 20,   nCores = 1 )  # S4 method for PrecisionPathways,MultiAssayExperimentOrList precisionPathwaysPredict(pathways, measurements, class)"},{"path":"/reference/precisionPathways.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Precision Pathways for Sample Prediction Based on Prediction Confidence. — precisionPathwaysTrain","text":"measurements Either MultiAssayExperiment list basic tabular objects containing data. class measurements training samples. measurements list, may also vector classes. useFeatures Default: NULL (.e. use provided features). named list features use. Otherwise, input data single table can just vector feature names. assays named list, features used. \"clinical\" also valid assay name refers clinical data table. allows avoidance variables spike-RNAs, sample IDs, sample acquisition dates, etc. relevant outcome prediction. maxMissingProp Default: 0.0. proportion less 1 maximum tolerated proportion missingness feature retained modelling. topNvariance Default: NULL. integer number variable features per assay subset . Assays less features reduced size. fixedAssays character vector assay names specifying assays must beginning pathway. confidenceCutoff minimum confidence predictions sample predicted particular issue . sample predicted belong particular class proportion \\(p\\) times, confidence \\(2 \\times |p - 0.5|\\). minAssaySamples integer specifying minimum number samples tier may . subsequent tier less number samples, samples incorporated current tier. nFeatures Default: 20. number features consider feature selection, feature selection done. selectionMethod named character vector feature selection methods use assays, one . names must correspond names measurements. classifier named character vector modelling methods use assays, one . names must correspond names measurements. nFolds numeric specifying number folds use cross-validation. nRepeats numeric specifying number repeats permutations use cross-validation. nCores numeric specifying number cores used user wants use parallelisation. pathways set pathways created precisionPathwaysTrain object class PrecisionPathways used predicting new data set.","code":""},{"path":"/reference/precisionPathways.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Precision Pathways for Sample Prediction Based on Prediction Confidence. — precisionPathwaysTrain","text":"object class PrecisionPathways basically named list plotting tabulating functions can use.","code":""},{"path":"/reference/precisionPathways.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Precision Pathways for Sample Prediction Based on Prediction Confidence. — precisionPathwaysTrain","text":"","code":"# To be determined."},{"path":"/reference/precisionPathwaysEvaluations.html","id":null,"dir":"Reference","previous_headings":"","what":"Various Functions for Evaluating Precision Pathways — calcCostsAndPerformance","title":"Various Functions for Evaluating Precision Pathways — calcCostsAndPerformance","text":"functions tabulate plot various aspects precision pathways, accuracies costs.","code":""},{"path":"/reference/precisionPathwaysEvaluations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Various Functions for Evaluating Precision Pathways — calcCostsAndPerformance","text":"","code":"calcCostsAndPerformance(precisionPathways, costs = NULL)  # S3 method for PrecisionPathways summary(object, weights = c(accuracy = 0.5, cost = 0.5), ...)  # S3 method for PrecisionPathways bubblePlot(precisionPathways, pathwayColours = NULL, ...)  # S3 method for PrecisionPathways flowchart(   precisionPathways,   pathway,   nodeColours = c(assay = \"#86C57C\", class1 = \"#ACCEE0\", class2 = \"#F47F72\"),   ... )  # S3 method for PrecisionPathways strataPlot(   precisionPathways,   pathway,   classColours = c(class1 = \"#4DAF4A\", class2 = \"#984EA3\"),   ... )"},{"path":"/reference/precisionPathwaysEvaluations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Various Functions for Evaluating Precision Pathways — calcCostsAndPerformance","text":"precisionPathways pathway class PrecisionPathways. costs named vector assays cost one. object set pathways class PrecisionPathways. weights numeric vector length two specifying weight predictive accuracy cost ranking. Must sum 1. ... used just following S3 requirement generic template. pathwayColours named vector colours names names pathways. none specified, default colour scheme automatically chosen. pathway chracter vector length 1 specifying pathway plot, e.g. \"clinical-mRNA\". nodeColours named vector colours names \"assay\", \"class1\",\"class2\". default colour scheme automatically chosen. classColours named vector colours names \"class1\",\"class2\", \"accuracy\". default colour scheme automatically chosen.","code":""},{"path":"/reference/prepareData.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Different Data Classes into DataFrame and Filter Features — prepareData","title":"Convert Different Data Classes into DataFrame and Filter Features — prepareData","text":"Input data matrix, MultiAssayExperiment, DataFrame format function prepare DataFrame features vector outcomes help exclude nuisance features dates unique sample identifiers subsequent modelling.","code":""},{"path":"/reference/prepareData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Different Data Classes into DataFrame and Filter Features — prepareData","text":"","code":"# S4 method for matrix prepareData(measurements, outcome, ...)  # S4 method for data.frame prepareData(measurements, outcome, ...)  # S4 method for DataFrame prepareData(   measurements,   outcome,   useFeatures = NULL,   maxMissingProp = 0,   topNvariance = NULL )  # S4 method for MultiAssayExperiment prepareData(measurements, outcomeColumns = NULL, useFeatures = NULL, ...)  # S4 method for list prepareData(measurements, outcome = NULL, useFeatures = NULL, ...)"},{"path":"/reference/prepareData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Different Data Classes into DataFrame and Filter Features — prepareData","text":"measurements Either matrix, DataFrame MultiAssayExperiment containing data. matrix DataFrame, rows samples, columns features. ... Variables used matrix MultiAssayExperiment method passed used DataFrame method. outcome Either factor vector classes, Surv object, character string, vector strings, containing column name(s) column(s) containing either classes time event information survival. column names survival information, time must first column event status second. useFeatures Default: NULL (.e. use provided features). measurements MultiAssayExperiment list tabular data, named list features use. Otherwise, input data single table can just vector feature names. assays named list, features used. \"clinical\" also valid assay name refers clinical data table. allows avoidance variables spike-RNAs, sample IDs, sample acquisition dates, etc. relevant outcome prediction. maxMissingProp Default: 0.0. proportion less 1 maximum tolerated proportion missingness feature retained modelling. topNvariance Default: NULL. measurements MultiAssayExperiment list tabular data, named integer vector variable  features per assay subset . input data single table, simply single integer. assays less features, reduced size stay -. outcomeColumns measurements MultiAssayExperiment, names column (class) columns (survival) table extracted colData(data) contain(s) individual's outcome use prediction.","code":""},{"path":"/reference/prepareData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Different Data Classes into DataFrame and Filter Features — prepareData","text":"list length two. first element DataFrame features second element outcomes use modelling.","code":""},{"path":"/reference/prepareData.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert Different Data Classes into DataFrame and Filter Features — prepareData","text":"Dario Strbenac","code":""},{"path":"/reference/rankingPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Pair-wise Overlap of Ranked Features — rankingPlot","title":"Plot Pair-wise Overlap of Ranked Features — rankingPlot","text":"Pair-wise overlaps can done two types analyses. Firstly, cross-validation iteration can considered within single classification. explores feature ranking stability. Secondly, overlap may considered different classification results. approach compares feature ranking commonality different results. Two types commonality possible analyse. One summary average pair-wise overlap possible pairs results. second kind summary pair-wise overlap level comparison factor reference level reference level. overlaps converted percentages plotted lineplots.","code":""},{"path":"/reference/rankingPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Pair-wise Overlap of Ranked Features — rankingPlot","text":"","code":"# S4 method for ClassifyResult rankingPlot(results, ...)  # S4 method for list rankingPlot(   results,   topRanked = seq(10, 100, 10),   comparison = \"within\",   referenceLevel = NULL,   characteristicsList = list(),   orderingList = list(),   sizesList = list(lineWidth = 1, pointSize = 2, legendLinesPointsSize = 1, fonts = c(24,     16, 12, 12, 12, 16)),   lineColours = NULL,   xLabelPositions = seq(10, 100, 10),   yMax = 100,   title = if (comparison[1] == \"within\") \"Feature Ranking Stability\" else     \"Feature Ranking Commonality\",   yLabel = if (is.null(referenceLevel)) \"Average Common Features (%)\" else     paste(\"Average Common Features with\", referenceLevel, \"(%)\"),   margin = grid::unit(c(1, 1, 1, 1), \"lines\"),   showLegend = TRUE,   parallelParams = bpparam() )"},{"path":"/reference/rankingPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Pair-wise Overlap of Ranked Features — rankingPlot","text":"results list ClassifyResult objects. ... used end user. topRanked sequence thresholds number best features use overlapping. comparison Default: \"within\". aspect experimental design compare. Can characteristic results share special value \"within\" compared pairwise iterations cross-validation. referenceLevel level comparison factor use reference compare non-reference level . NULL, level average pairwise overlap calculated levels. characteristicsList named list characteristics. name must one \"lineColour\", \"pointType\", \"row\" \"column\". value element must characteristic name, stored \"characteristic\" column results' characteristics table. orderingList optional named list. variables specified characteristicsList can name element list value element order factor presented . sizesList Default: lineWidth = 1, pointSize = 2, legendLinesPointsSize = 1, fonts = c(24, 16, 12, 12, 12, 16). list must contain elements named lineWidth, pointSize, legendLinesPointsSize fonts. first three specify size lines points graph, well plot legend. fonts vector length 6.  first element size title text. second element size axes titles.  third element size axes values. fourth element size legends' titles.  fifth element font size legend labels. sixth element font size titles grouped plots, produced. list element must numeric. lineColours vector colours different levels line colouring parameter, one specified characteristicsList[[\"lineColour\"]]. none specified , characteristicsList[[\"lineColour\"]] , automatically-generated palette used. xLabelPositions Locations put labels x-axis. yMax maximum value percentage plot. title overall title plot. yLabel Label used y-axis overlap percentages. margin margin around plot. showLegend TRUE, legend plotted next plot. FALSE, hidden. parallelParams object class MulticoreParam SnowParam.","code":""},{"path":"/reference/rankingPlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Pair-wise Overlap of Ranked Features — rankingPlot","text":"object class ggplot plot current graphics device, plot TRUE.","code":""},{"path":"/reference/rankingPlot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Pair-wise Overlap of Ranked Features — rankingPlot","text":"comparison \"within\", feature selection overlaps compared within particular analysis. result inform stable selections different iterations cross-validation particular analysis. Otherwise, comparison different cross-validation runs, gives indication common features selected different classifications. Calculating pair-wise set overlaps large cross-validation result can time-consuming.  stage can done multiple CPUs providing relevant options parallelParams.","code":""},{"path":"/reference/rankingPlot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Pair-wise Overlap of Ranked Features — rankingPlot","text":"Dario Strbenac","code":""},{"path":"/reference/rankingPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Pair-wise Overlap of Ranked Features — rankingPlot","text":"","code":"predicted <- DataFrame(sample = sample(10, 100, replace = TRUE),                           permutation = rep(1:2, each = 50),                           class = rep(c(\"Healthy\", \"Cancer\"), each = 50))   actual <- factor(rep(c(\"Healthy\", \"Cancer\"), each = 5))   allFeatures <- sapply(1:100, function(index) paste(sample(LETTERS, 3), collapse = ''))   rankList <- list(allFeatures[1:100], allFeatures[c(15:6, 1:5, 16:100)],                    allFeatures[c(1:9, 11, 10, 12:100)], allFeatures[c(1:50, 61:100, 60:51)])   result1 <- ClassifyResult(DataFrame(characteristic = c(\"Data Set\", \"Selection Name\", \"Classifier Name\", \"Cross-validation\"),                             value = c(\"Melanoma\", \"t-test\", \"Diagonal LDA\", \"2 Permutations, 2 Folds\")),                             LETTERS[1:10], allFeatures, rankList,                             list(rankList[[1]][1:15], rankList[[2]][1:15],                                  rankList[[3]][1:10], rankList[[4]][1:10]),                             list(function(oracle){}), NULL,                             predicted, actual)      predicted[, \"class\"] <- sample(predicted[, \"class\"])   rankList <- list(allFeatures[1:100], allFeatures[c(sample(20), 21:100)],   allFeatures[c(1:9, 11, 10, 12:100)], allFeatures[c(1:50, 60:51, 61:100)])   result2 <- ClassifyResult(DataFrame(characteristic = c(\"Data Set\", \"Selection Name\", \"Classifier Name\",                                                          \"Cross-validations\"),                             value = c(\"Melanoma\", \"t-test\", \"Random Forest\", \"2 Permutations, 2 Folds\")),                             LETTERS[1:10], allFeatures, rankList,                             list(rankList[[1]][1:15], rankList[[2]][1:15],                                  rankList[[3]][1:10], rankList[[4]][1:10]),                             list(function(oracle){}), NULL,                             predicted, actual)                                rankingPlot(list(result1, result2), characteristicsList = list(pointType = \"Classifier Name\"))"},{"path":"/reference/runTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform a Single Classification — runTest","title":"Perform a Single Classification — runTest","text":"data set features samples, classification process run. consists data transformation, feature selection, classifier training testing.","code":""},{"path":"/reference/runTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform a Single Classification — runTest","text":"","code":"# S4 method for matrix runTest(measurementsTrain, outcomeTrain, measurementsTest, outcomeTest, ...)  # S4 method for DataFrame runTest(   measurementsTrain,   outcomeTrain,   measurementsTest,   outcomeTest,   crossValParams = CrossValParams(),   modellingParams = ModellingParams(),   characteristics = S4Vectors::DataFrame(),   ...,   verbose = 1,   .iteration = NULL )  # S4 method for MultiAssayExperiment runTest(measurementsTrain, measurementsTest, outcomeColumns, ...)"},{"path":"/reference/runTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform a Single Classification — runTest","text":"measurementsTrain Either matrix, DataFrame MultiAssayExperiment containing training data. matrix DataFrame, rows samples, columns features. ... Variables used matrix MultiAssayExperiment method passed used DataFrame method passed onwards prepareData. outcomeTrain Either factor vector classes, Surv object, character string, vector strings, containing column name(s) column(s) containing either classes time event information survival. column names survival information, time must first column event status second. measurementsTest data type measurementsTrain, test samples. outcomeTest data type outcomeTrain, test samples. crossValParams object class CrossValParams, specifying kind cross-validation done, nested cross-validation used tune parameters. modellingParams object class ModellingParams, specifying class rebalancing, transformation (), feature selection (), training prediction done data set. characteristics DataFrame describing characteristics classification used. First column must named \"charateristic\" second column must named \"value\". Useful automated plot annotation plotting functions within package. Transformation, selection prediction functions provided package cause characteristics automatically determined can left blank. verbose Default: 1. number 0 3 amount progress messages give.  higher number produce messages lower-level functions print messages. .iteration set user. value used keep track cross-validation iteration, called runTests. outcomeColumns measurementsTrain MultiAssayExperiment, names column (class) columns (survival) table extracted colData(data) contain(s) samples' outcome use prediction.","code":""},{"path":"/reference/runTest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform a Single Classification — runTest","text":"called directly user rather used internally runTests, ClassifyResult object. Otherwise list different aspects result passed back runTests.","code":""},{"path":"/reference/runTest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform a Single Classification — runTest","text":"function performs one classification prediction. See runTests driver function enables number different cross-validation schemes applied uses function perform iteration.","code":""},{"path":"/reference/runTest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Perform a Single Classification — runTest","text":"Dario Strbenac","code":""},{"path":"/reference/runTest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform a Single Classification — runTest","text":"","code":"#if(require(sparsediscrim))   #{     data(asthma)     tuneList <- list(nFeatures = seq(5, 25, 5), performanceType = \"Balanced Error\")     selectParams <- SelectParams(\"limma\", tuneParams = tuneList)     modellingParams <- ModellingParams(selectParams = selectParams)     trainIndices <- seq(1, nrow(measurements), 2)     testIndices <- seq(2, nrow(measurements), 2)          runTest(measurements[trainIndices, ], classes[trainIndices],             measurements[testIndices, ], classes[testIndices], modellingParams = modellingParams) #> An object of class 'ClassifyResult'. #> Characteristics: #>    characteristic             value #>              topN                 5 #>    Balanced Error 0.102941176470588 #>    Selection Name  Moderated t-test #>   Classifier Name      Diagonal LDA #>  Cross-validation   Independent Set #> Features: List of length 1 of feature identifiers. #> Predictions: A data frame of 95 rows. #> Performance Measures: None calculated yet.   #}"},{"path":"/reference/runTests.html","id":null,"dir":"Reference","previous_headings":"","what":"Reproducibly Run Various Kinds of Cross-Validation — runTests","title":"Reproducibly Run Various Kinds of Cross-Validation — runTests","text":"Enables classification schemes ordinary 10-fold, 100 permutations 5-fold, leave one cross-validation. Processing parallel possible leveraging package BiocParallel.","code":""},{"path":"/reference/runTests.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reproducibly Run Various Kinds of Cross-Validation — runTests","text":"","code":"# S4 method for matrix runTests(measurements, outcome, ...)  # S4 method for DataFrame runTests(   measurements,   outcome,   crossValParams = CrossValParams(),   modellingParams = ModellingParams(),   characteristics = S4Vectors::DataFrame(),   ...,   verbose = 1 )  # S4 method for MultiAssayExperiment runTests(measurements, outcome, ...)"},{"path":"/reference/runTests.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reproducibly Run Various Kinds of Cross-Validation — runTests","text":"measurements Either matrix, DataFrame MultiAssayExperiment containing data. matrix DataFrame, rows samples, columns features. ... Variables used matrix MultiAssayExperiment method passed used DataFrame method passed onwards prepareData. outcome Either factor vector classes, Surv object, character string, vector strings, containing column name(s) column(s) containing either classes time event information survival. measurements MultiAssayExperiment, names column (class) columns (survival) table extracted colData(data) contain(s) samples' outcome use prediction. column names survival information, time must first column event status second. crossValParams object class CrossValParams, specifying kind cross-validation done. modellingParams object class ModellingParams, specifying class rebalancing, transformation (), feature selection (), training prediction done data set. characteristics DataFrame describing characteristics classification used. First column must named \"charateristic\" second column must named \"value\". Useful automated plot annotation plotting functions within package.  Transformation, selection prediction functions provided package cause characteristics automatically determined can left blank. verbose Default: 1. number 0 3 amount progress messages give.  higher number produce messages lower-level functions print messages.","code":""},{"path":"/reference/runTests.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reproducibly Run Various Kinds of Cross-Validation — runTests","text":"object class ClassifyResult.","code":""},{"path":"/reference/runTests.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Reproducibly Run Various Kinds of Cross-Validation — runTests","text":"Dario Strbenac","code":""},{"path":"/reference/runTests.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reproducibly Run Various Kinds of Cross-Validation — runTests","text":"","code":"#if(require(sparsediscrim))   #{     data(asthma)          CVparams <- CrossValParams(permutations = 5)     tuneList <- list(nFeatures = seq(5, 25, 5), performanceType = \"Balanced Error\")     selectParams <- SelectParams(\"t-test\", tuneParams = tuneList)     modellingParams <- ModellingParams(selectParams = selectParams)     runTests(measurements, classes, CVparams, modellingParams,              DataFrame(characteristic = c(\"Assay Name\", \"Classifier Name\"),                        value = c(\"Asthma\", \"Different Means\"))              ) #> An object of class 'ClassifyResult'. #> Characteristics: #>    characteristic                   value #>        Assay Name                  Asthma #>   Classifier Name         Different Means #>    Selection Name     Difference in Means #>  Cross-validation 5 Permutations, 5 Folds #> Features: List of length 25 of feature identifiers. #> Predictions: A data frame of 950 rows. #> Performance Measures: None calculated yet.   #}"},{"path":"/reference/samplesMetricMap.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a Grid of Sample Error Rates or Accuracies — samplesMetricMap","title":"Plot a Grid of Sample Error Rates or Accuracies — samplesMetricMap","text":"grid coloured tiles drawn. one column sample one row classification result.","code":""},{"path":"/reference/samplesMetricMap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a Grid of Sample Error Rates or Accuracies — samplesMetricMap","text":"","code":"# S4 method for ClassifyResult samplesMetricMap(results, ...)  # S4 method for list samplesMetricMap(   results,   comparison = \"auto\",   metric = \"auto\",   featureValues = NULL,   featureName = NULL,   metricColours = list(c(\"#FFFFFF\", \"#CFD1F2\", \"#9FA3E5\", \"#6F75D8\", \"#3F48CC\"),     c(\"#FFFFFF\", \"#E1BFC4\", \"#C37F8A\", \"#A53F4F\", \"#880015\")),   classColours = c(\"#3F48CC\", \"#880015\"),   groupColours = c(\"darkgreen\", \"yellow2\"),   fontSizes = c(24, 16, 12, 12, 12),   mapHeight = 4,   title = switch(metric, `Sample Error` = \"Error Comparison\", `Sample Accuracy` =     \"Accuracy Comparison\", `Sample C-index` = \"Risk Score Comparison\"),   showLegends = TRUE,   xAxisLabel = \"Sample Name\",   showXtickLabels = TRUE,   yAxisLabel = \"Analysis\",   showYtickLabels = TRUE,   legendSize = grid::unit(1, \"lines\"),   plot = TRUE )  # S4 method for matrix samplesMetricMap(   results,   classes,   metric = c(\"Sample Error\", \"Sample Accuracy\"),   featureValues = NULL,   featureName = NULL,   metricColours = list(c(\"#3F48CC\", \"#6F75D8\", \"#9FA3E5\", \"#CFD1F2\", \"#FFFFFF\"),     c(\"#880015\", \"#A53F4F\", \"#C37F8A\", \"#E1BFC4\", \"#FFFFFF\")),   classColours = c(\"#3F48CC\", \"#880015\"),   groupColours = c(\"darkgreen\", \"yellow2\"),   fontSizes = c(24, 16, 12, 12, 12),   mapHeight = 4,   title = \"Error Comparison\",   showLegends = TRUE,   xAxisLabel = \"Sample Name\",   showXtickLabels = TRUE,   yAxisLabel = \"Analysis\",   showYtickLabels = TRUE,   legendSize = grid::unit(1, \"lines\"),   plot = TRUE )"},{"path":"/reference/samplesMetricMap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a Grid of Sample Error Rates or Accuracies — samplesMetricMap","text":"results list ClassifyResult objects. also matrix pre-calculated metrics, backwards compatibility. ... Parameters used ClassifyResult method list-packaging used main list method. comparison Default: \"auto\". aspect experimental design compare. Can characteristic results share. metric Default: \"auto\". name performance measure \"auto\". results classification sample accuracy displayed. Otherwise, results survival risk predictions sample C-index displayed. Valid values \"Sample Error\", \"Sample Error\" \"Sample C-index\". metric stored results list, performance metric calculated automatically. featureValues NULL, can named factor named numeric vector specifying variable interest plot heatmap. featureName label describing information featureValues. must specified featureValues . metricColours outcome categorical, list vectors colours metric levels class. outcome numeric, risk score, single vector colours metric levels samples. classColours Either vector colours class levels classes colour, list length 2, component vector length. vector colour gradient class. groupColours vector colours group levels. useful featureValues NULL. fontSizes vector length 5. first number size title.  second number size axes titles. third number size axes values. fourth number size legends' titles. fifth number font size legend labels. mapHeight Height map, relative height class colour bar. title title place plot. showLegends Logical. FALSE, legend drawn. xAxisLabel name plotted x-axis. NULL suppresses label. showXtickLabels Logical. FALSE, x-axis labels hidden. yAxisLabel name plotted y-axis. NULL suppresses label. showYtickLabels Logical. FALSE, y-axis labels hidden. legendSize size boxes legends. plot Logical. TRUE, plot produced current graphics device. classes results matrix, factor vector length number columns results .","code":""},{"path":"/reference/samplesMetricMap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a Grid of Sample Error Rates or Accuracies — samplesMetricMap","text":"plot produced grob returned can saved graphics device.","code":""},{"path":"/reference/samplesMetricMap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot a Grid of Sample Error Rates or Accuracies — samplesMetricMap","text":"names results determine row names plot. length metricColours determines many bins metric values discretised .","code":""},{"path":"/reference/samplesMetricMap.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot a Grid of Sample Error Rates or Accuracies — samplesMetricMap","text":"Dario Strbenac","code":""},{"path":"/reference/samplesMetricMap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a Grid of Sample Error Rates or Accuracies — samplesMetricMap","text":"","code":"predicted <- DataFrame(sample = LETTERS[sample(10, 100, replace = TRUE)],                           class = rep(c(\"Healthy\", \"Cancer\"), each = 50))   actual <- factor(rep(c(\"Healthy\", \"Cancer\"), each = 5), levels = c(\"Healthy\", \"Cancer\"))   features <- sapply(1:100, function(index) paste(sample(LETTERS, 3), collapse = ''))   result1 <- ClassifyResult(DataFrame(characteristic = c(\"Data Set\", \"Selection Name\", \"Classifier Name\",                                                          \"Cross-validation\"),                             value = c(\"Example\", \"t-test\", \"Differential Expression\", \"2 Permutations, 2 Folds\")),                             LETTERS[1:10], features, list(1:100), list(sample(10, 10)),                             list(function(oracle){}), NULL, predicted, actual)   predicted[, \"class\"] <- sample(predicted[, \"class\"])   result2 <- ClassifyResult(DataFrame(characteristic = c(\"Data Set\", \"Selection Name\", \"Classifier Name\",                                                          \"Cross-validation\"),                             value = c(\"Example\", \"Bartlett Test\", \"Differential Variability\", \"2 Permutations, 2 Folds\")),                             LETTERS[1:10], features, list(1:100), list(sample(10, 10)),                             list(function(oracle){}), NULL, predicted, actual)   result1 <- calcCVperformance(result1)   result2 <- calcCVperformance(result2)   groups <- factor(rep(c(\"Male\", \"Female\"), length.out = 10))   names(groups) <- LETTERS[1:10]   cholesterol <- c(4.0, 5.5, 3.9, 4.9, 5.7, 7.1, 7.9, 8.0, 8.5, 7.2)   names(cholesterol) <- LETTERS[1:10]      wholePlot <- samplesMetricMap(list(Gene = result1, Protein = result2)) #> Warning: Sample Accuracy not found in all elements of results. Calculating it now. #> Warning: Removed 2 rows containing missing values (`geom_tile()`).   wholePlot <- samplesMetricMap(list(Gene = result1, Protein = result2),                                 featureValues = groups, featureName = \"Gender\") #> Warning: Sample Accuracy not found in all elements of results. Calculating it now. #> Warning: Removed 2 rows containing missing values (`geom_tile()`). #> Warning: Removed 2 rows containing missing values (`geom_tile()`).   wholePlot <- samplesMetricMap(list(Gene = result1, Protein = result2),                                 featureValues = cholesterol, featureName = \"Cholesterol\")                                 #> Warning: Sample Accuracy not found in all elements of results. Calculating it now. #> Warning: Removed 2 rows containing missing values (`geom_tile()`)."},{"path":"/reference/selectionPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Pair-wise Overlap, Variable Importance or Selection Size Distribution of Selected Features — selectionPlot","title":"Plot Pair-wise Overlap, Variable Importance or Selection Size Distribution of Selected Features — selectionPlot","text":"Pair-wise overlaps can done two types analyses. Firstly, cross-validation iteration can considered within single classification. explores feature selection stability. Secondly, overlap may considered different classification results. approach compares feature selection commonality different selection methods. Two types commonality possible analyse. One summary average pair-wise overlap levels comparison factor summary pair-wise overlap level comparison factor reference level reference level. overlaps converted percentages plotted lineplots.","code":""},{"path":"/reference/selectionPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Pair-wise Overlap, Variable Importance or Selection Size Distribution of Selected Features — selectionPlot","text":"","code":"# S4 method for ClassifyResult selectionPlot(results, ...)  # S4 method for list selectionPlot(   results,   comparison = \"within\",   referenceLevel = NULL,   characteristicsList = list(x = \"auto\"),   coloursList = list(),   orderingList = list(),   binsList = list(),   yMax = 100,   fontSizes = c(24, 16, 12, 16),   title = if (comparison == \"within\") \"Feature Selection Stability\" else if (comparison     == \"size\") \"Feature Selection Size\" else if (comparison == \"importance\")     \"Variable Importance\" else \"Feature Selection Commonality\",   yLabel = if (is.null(referenceLevel) && !comparison %in% c(\"size\", \"importance\"))     \"Common Features (%)\" else if (comparison == \"size\") \"Set Size\" else if (comparison     == \"importance\") tail(names(results[[1]]@importance), 1) else     paste(\"Common Features with\", referenceLevel, \"(%)\"),   margin = grid::unit(c(1, 1, 1, 1), \"lines\"),   rotate90 = FALSE,   showLegend = TRUE,   plot = TRUE,   parallelParams = bpparam() )"},{"path":"/reference/selectionPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Pair-wise Overlap, Variable Importance or Selection Size Distribution of Selected Features — selectionPlot","text":"results list ClassifyResult objects. ... used end user. comparison Default: \"within\". aspect experimental design compare. Can characteristic results share either one special values \"within\" compare pairwise iterations cross-validation. \"size\", draw bar chart frequency selected set sizes, \"importance\" plot variable importance scores selected variables. \"importance\" usable doImportance TRUE cross-validation. referenceLevel level comparison factor use reference compare non-reference level . NULL, level average pairwise overlap calculated levels. characteristicsList named list characteristics. element's name must one \"x\", \"row\", \"column\", \"fillColour\", \"lineColour\". value element must characteristic name, stored \"characteristic\" column results' characteristics table. \"x\" mandatory. \"auto\" default, identify characteristic unique value element results. coloursList named list plot aspects colours aspects. elements mandatory. specified, list element's name must either \"fillColours\" \"lineColours\". characteristic associated fill line characteristicsList list empty, palette colours automaticaly chosen. orderingList optional named list. variables specified characteristicsList can name element list value element order factors presented , case alphabetical sorting undesirable. binsList Used comparison \"size\". list elements named \"setSizes\" \"frequencies\" elements mandatory. \"setSizes\" specifies bin boundaries bins interest feature selection sizes (e.g. 0, 10, 20, 30). \"frequencies\" specifies bin boundaries relative frequency percentages plot (e.g. 0, 20, 40, 60, 80, 100). yMax Used comparison \"size\". maximum value percentage overlap plot. fontSizes vector length 4. first number size title.  second number size axes titles. third number size axes values. fourth number font size titles grouped plots, produced. words, rowVariable columnVariable NULL. title overall title plot. default, specifies whether stability commonality shown. yLabel Label used y-axis overlap percentages. default, specifies whether stability commonality shown. margin margin around plot. rotate90 Logical. TRUE, boxplot horizontal. showLegend TRUE, legend plotted next plot. FALSE, hidden. plot Logical. TRUE, plot produced current graphics device. parallelParams object class MulticoreParam SnowParam.","code":""},{"path":"/reference/selectionPlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Pair-wise Overlap, Variable Importance or Selection Size Distribution of Selected Features — selectionPlot","text":"object class ggplot plot current graphics device, plot TRUE.","code":""},{"path":"/reference/selectionPlot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Pair-wise Overlap, Variable Importance or Selection Size Distribution of Selected Features — selectionPlot","text":"Additionally, heatmap selection size frequencies can made specifying size comparison make. Lastly, plot showing distribution performance metric changes features excluded training can made variable importance calculation turned cross-validation. comparison \"within\", feature selection overlaps compared within particular analysis. result inform stable selections different iterations cross-validation particular analysis. Otherwise, comparison different cross-validation runs, gives indication common features selected different classifications. Calculating pair-wise set overlaps can time-consuming. stage can done multiple CPUs providing relevant options parallelParams. percentage calculated intersection two sets features divided union sets, multiplied 100. feature selection size mode, binsList used create bins include lowest value first bin, highest value last bin using cut.","code":""},{"path":"/reference/selectionPlot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Pair-wise Overlap, Variable Importance or Selection Size Distribution of Selected Features — selectionPlot","text":"Dario Strbenac","code":""},{"path":"/reference/selectionPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Pair-wise Overlap, Variable Importance or Selection Size Distribution of Selected Features — selectionPlot","text":"","code":"predicted <- DataFrame(sample = sample(10, 100, replace = TRUE),                           class = rep(c(\"Healthy\", \"Cancer\"), each = 50))   actual <- factor(rep(c(\"Healthy\", \"Cancer\"), each = 5))   allFeatures <- sapply(1:100, function(index) paste(sample(LETTERS, 3), collapse = ''))   rankList <- list(allFeatures[1:100], allFeatures[c(5:1, 6:100)],                    allFeatures[c(1:9, 11, 10, 12:100)], allFeatures[c(1:50, 60:51, 61:100)])   result1 <- ClassifyResult(DataFrame(characteristic = c(\"Data Set\", \"Selection Name\", \"Classifier Name\",                                                          \"Cross-validations\"),                             value = c(\"Melanoma\", \"t-test\", \"Random Forest\", \"2 Permutations, 2 Folds\")),                             LETTERS[1:10], allFeatures, rankList,                             list(rankList[[1]][1:15], rankList[[2]][1:15],                                  rankList[[3]][1:10], rankList[[4]][1:10]),                             list(function(oracle){}), NULL,                             predicted, actual)      predicted[, \"class\"] <- sample(predicted[, \"class\"])   rankList <- list(allFeatures[1:100], allFeatures[c(sample(20), 21:100)],                    allFeatures[c(1:9, 11, 10, 12:100)], allFeatures[c(1:50, 60:51, 61:100)])   result2 <- ClassifyResult(DataFrame(characteristic = c(\"Data Set\", \"Selection Name\", \"Classifier Name\",                                                          \"Cross-validation\"),                             value = c(\"Melanoma\", \"t-test\", \"Diagonal LDA\", \"2 Permutations, 2 Folds\")),                             LETTERS[1:10], allFeatures, rankList,                             list(rankList[[1]][1:15], rankList[[2]][1:25],                                  rankList[[3]][1:10], rankList[[4]][1:10]),                             list(function(oracle){}), NULL,                             predicted, actual)   cList <- list(x = \"Classifier Name\", fillColour = \"Classifier Name\")   selectionPlot(list(result1, result2), characteristicsList = cList)        cList <- list(x = \"Classifier Name\", fillColour = \"size\")   selectionPlot(list(result1, result2), comparison = \"size\",                 characteristicsList = cList,                 binsList = list(frequencies = seq(0, 100, 10), setSizes = seq(0, 25, 5))                 )"}]
